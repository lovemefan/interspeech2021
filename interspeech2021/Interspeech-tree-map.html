<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Awesome-pyecharts</title>
            <script type="text/javascript" src="https://assets.pyecharts.org/assets/echarts.min.js"></script>

</head>
<body>
    <div id="f8402b66578a40179f060f6f7c91380f" class="chart-container" style="width:1900px; height:890px;"></div>
    <script>
        var chart_f8402b66578a40179f060f6f7c91380f = echarts.init(
            document.getElementById('f8402b66578a40179f060f6f7c91380f'), 'white', {renderer: 'canvas'});
        var option_f8402b66578a40179f060f6f7c91380f = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    "series": [
        {
            "type": "treemap",
            "name": "option",
            "data": [
                {
                    "name": "Speech Synthesis",
                    "children": [
                        {
                            "name": "Speech Synthesis: Other Topics",
                            "children": [
                                {
                                    "name": " Conversion of Airborne to Bone-Conducted Speech with Deep Neural Networks",
                                    "value": 1
                                },
                                {
                                    "name": " T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Evaluating the Extrapolation Capabilities of Neural Vocoders to Extreme Pitch Values",
                                    "value": 1
                                },
                                {
                                    "name": " A Systematic Review and Analysis of Multilingual Data Strategies in Text-to-Speech for Low-Resource Languages",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Speech Synthesis: Toward End-to-End Synthesis  II",
                            "children": [
                                {
                                    "name": " TacoLPCNet: Fast and Stable TTS by Conditioning LPCNet on Mel Spectrogram Predictions",
                                    "value": 1
                                },
                                {
                                    "name": " FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Sequence-to-Sequence Learning for Deep Gaussian Process Based Speech Synthesis Using Self-Attention GP Layer",
                                    "value": 1
                                },
                                {
                                    "name": " Phonetic and Prosodic Information Estimation from Texts for Genuine Japanese End-to-End Text-to-Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Information Sieve: Content Leakage Reduction in End-to-End Prosody Transfer for Expressive Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Deliberation-Based Multi-Pass Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Parallel Tacotron 2: A Non-Autoregressive Neural TTS Model with Differentiable Duration Modeling",
                                    "value": 1
                                },
                                {
                                    "name": " Transformer-Based Acoustic Modeling for Streaming Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS",
                                    "value": 1
                                },
                                {
                                    "name": " Speed up Training with Variable Length Inputs by Efficient Batching Strategies",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        },
                        {
                            "name": "Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis",
                            "children": [
                                {
                                    "name": " N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Lingual Low Resource Speaker Adaptation Using Phonological Features",
                                    "value": 1
                                },
                                {
                                    "name": " Improve Cross-Lingual Text-To-Speech Synthesis on Monolingual Corpora with Pitch Contour Information",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Lingual Voice Conversion with Disentangled Universal Linguistic Representations",
                                    "value": 1
                                },
                                {
                                    "name": " EfficientSing: A Chinese Singing Voice Synthesis System Using Duration-Free Acoustic Model and HiFi-GAN Vocoder",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Lingual Speaker Adaptation Using Domain Adaptation and Speaker Consistency Loss for Text-To-Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating Contributions of Speech and Facial Landmarks for Talking Head Generation",
                                    "value": 1
                                },
                                {
                                    "name": " Speech2Video: Cross-Modal Distillation for Speech to Video Generation",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        },
                        {
                            "name": "Speech Synthesis: Neural Waveform Generation",
                            "children": [
                                {
                                    "name": " GAN Vocoder: Multi-Resolution Discriminator Is All You Need",
                                    "value": 1
                                },
                                {
                                    "name": " Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Unified Source-Filter GAN: Unified Source-Filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN",
                                    "value": 1
                                },
                                {
                                    "name": " Harmonic WaveGAN: GAN-Based Speech Waveform Generation Model with Harmonic Structure Discriminator",
                                    "value": 1
                                },
                                {
                                    "name": " Fre-GAN: Adversarial Frequency-Consistent Audio Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation",
                                    "value": 1
                                },
                                {
                                    "name": " Continuous Wavelet Vocoder-Based Decomposition of Parametric Speech Waveform Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " High-Fidelity and Low-Latency Universal Neural Vocoder Based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling",
                                    "value": 1
                                },
                                {
                                    "name": " Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition",
                                    "value": 1
                                },
                                {
                                    "name": " High-Fidelity Parallel WaveGAN with Multi-Band Harmonic-Plus-Noise Model",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Speech Synthesis: Tools, Data, Evaluation",
                            "children": [
                                {
                                    "name": " Spectral and Latent Speech Representation Distortion for TTS Evaluation",
                                    "value": 1
                                },
                                {
                                    "name": " Detection and Analysis of Attention Errors in Sequence-to-Sequence Text-to-Speech",
                                    "value": 1
                                },
                                {
                                    "name": " RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " AISHELL-3: A Multi-Speaker Mandarin TTS Corpus",
                                    "value": 1
                                },
                                {
                                    "name": " Comparing Speech Enhancement Techniques for Voice Adaptation-Based Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model",
                                    "value": 1
                                },
                                {
                                    "name": " Perception of Social Speaker Characteristics in Synthetic Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Hi-Fi Multi-Speaker English TTS Dataset",
                                    "value": 1
                                },
                                {
                                    "name": " Utilizing Self-Supervised Representations for MOS Prediction",
                                    "value": 1
                                },
                                {
                                    "name": " KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset",
                                    "value": 1
                                },
                                {
                                    "name": " Confidence Intervals for ASR-Based TTS Evaluation",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Speech Synthesis: Prosody Modeling  I",
                            "children": [
                                {
                                    "name": " Phrase Break Prediction with Bidirectional Encoder Representations in Japanese Text-to-Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Multi-Speaker TTS Prosody Variance with a Residual Encoder and Normalizing Flows",
                                    "value": 1
                                },
                                {
                                    "name": " Rich Prosody Diversity Modelling with Phone-Level Mixture Density Network",
                                    "value": 1
                                },
                                {
                                    "name": " Phoneme Duration Modeling Using Speech Rhythm-Based Speaker Embeddings for Multi-Speaker Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Fine-Grained Prosody Modeling in Neural Speech Synthesis Using ToBI Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Intra-Sentential Speaking Rate Control in Neural Text-To-Speech for Automatic Dubbing",
                                    "value": 1
                                },
                                {
                                    "name": " Applying the Information Bottleneck Principle to Prosodic Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " A Prototypical Network Approach for Evaluating Generated Emotional Speech",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        },
                        {
                            "name": "Speech Synthesis: Toward End-to-End Synthesis   I",
                            "children": [
                                {
                                    "name": " Federated Learning with Dynamic Transformer for Text to Speech",
                                    "value": 1
                                },
                                {
                                    "name": " LiteTTS: A Lightweight Mel-Spectrogram-Free Text-to-Wave Synthesizer Based on Generative Adversarial Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration",
                                    "value": 1
                                },
                                {
                                    "name": " Diff-TTS: A Denoising Diffusion Model for Text-to-Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
                                    "value": 1
                                },
                                {
                                    "name": " A Learned Conditional Prior for the VAE Acoustic Space of a TTS System",
                                    "value": 1
                                },
                                {
                                    "name": " A Universal Multi-Speaker Multi-Style Text-to-Speech via Disentangled Representation Learning Based on R\u00e9nyi Divergence Minimization",
                                    "value": 1
                                },
                                {
                                    "name": " Relational Data Selection for Data Augmentation of Speaker-Dependent Multi-Band MelGAN Vocoder",
                                    "value": 1
                                },
                                {
                                    "name": " Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Triple M: A Practical Text-to-Speech Synthesis System with Multi-Guidance Attention and Multi-Band Multi-Time LPCNet",
                                    "value": 1
                                },
                                {
                                    "name": " SC-GlowTTS: An Efficient Zero-Shot Multi-Speaker Text-To-Speech Model",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        },
                        {
                            "name": "Speech Synthesis: Prosody Modeling  II",
                            "children": [
                                {
                                    "name": " Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input",
                                    "value": 1
                                },
                                {
                                    "name": " Exploring Emotional Prototypes in a High Dimensional TTS Latent Space",
                                    "value": 1
                                },
                                {
                                    "name": " Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " ADEPT: A Dataset for Evaluating Prosody Transfer",
                                    "value": 1
                                },
                                {
                                    "name": " Prosodic Boundary Prediction Model for Vietnamese Text-To-Speech",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        },
                        {
                            "name": "Speech Synthesis: Linguistic Processing, Paradigms and Other Topics",
                            "children": [
                                {
                                    "name": " Unsupervised Learning of Disentangled Speech Content and Style Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Label Embedding for Chinese Grapheme-to-Phoneme Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " PDF: Polyphone Disambiguation in Chinese by Using FLAT",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Polyphone Disambiguation for Mandarin Chinese by Combining Mix-Pooling Strategy and Window-Based Attention",
                                    "value": 1
                                },
                                {
                                    "name": " Polyphone Disambiguation in Mandarin Chinese with Semi-Supervised Learning",
                                    "value": 1
                                },
                                {
                                    "name": " A Neural-Network-Based Approach to Identifying Speakers in Novels",
                                    "value": 1
                                },
                                {
                                    "name": " UnitNet-Based Hybrid Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Dynamically Adaptive Machine Speech Chain Inference for TTS in Noisy Environment: Listen and Speak Louder",
                                    "value": 1
                                },
                                {
                                    "name": " LinearSpeech: Parallel Text-to-Speech with Linear Complexity",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        },
                        {
                            "name": "Speech Synthesis: Speaking Style and Emotion",
                            "children": [
                                {
                                    "name": " STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability",
                                    "value": 1
                                },
                                {
                                    "name": " Emotional Prosody Control for Speech Generation",
                                    "value": 1
                                },
                                {
                                    "name": " Controllable Context-Aware Conversational Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Expressive Text-to-Speech Using Style Tag",
                                    "value": 1
                                },
                                {
                                    "name": " Adaptive Text to Speech for Spontaneous Style",
                                    "value": 1
                                },
                                {
                                    "name": " Towards Multi-Scale Style Control for Expressive Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Speaker Style Transfer with Prosody Bottleneck in Neural Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Fine-Grained Style Modeling, Transfer and Prediction in Text-to-Speech Synthesis via Phone-Level Content-Style Disentanglement",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Performance of Seen and Unseen Speech Style Transfer in End-to-End Neural TTS",
                                    "value": 1
                                },
                                {
                                    "name": " Synthesis of Expressive Speaking Styles with Limited Training Data in a Multi-Speaker, Prosody-Controllable Sequence-to-Sequence Architecture",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 90
                },
                {
                    "name": "Disordered Speech",
                    "children": [
                        {
                            "name": "Disordered Speech",
                            "children": [
                                {
                                    "name": " Acoustic Indicators of Speech Motor Coordination in Adults With and Without Traumatic Brain Injury",
                                    "value": 1
                                },
                                {
                                    "name": " On Modeling Glottal Source Information for Phonation Assessment in Parkinson\u2019s Disease",
                                    "value": 1
                                },
                                {
                                    "name": " Distortion of Voiced Obstruents for Differential Diagnosis Between Parkinson\u2019s Disease and Multiple System Atrophy",
                                    "value": 1
                                },
                                {
                                    "name": " A Study into Pre-Training Strategies for Spoken Language Understanding on Dysarthric Speech",
                                    "value": 1
                                },
                                {
                                    "name": " EasyCall Corpus: A Dysarthric Speech Dataset",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        }
                    ],
                    "value": 5
                },
                {
                    "name": "Speech Signal Analysis and Representation",
                    "children": [
                        {
                            "name": "Speech Signal Analysis and Representation : II",
                            "children": [
                                {
                                    "name": " A Benchmark of Dynamical Variational Autoencoders Applied to Speech Spectrogram Modeling",
                                    "value": 1
                                },
                                {
                                    "name": " Fricative Phoneme Detection Using Deep Neural Networks and its Comparison to Traditional Methods",
                                    "value": 1
                                },
                                {
                                    "name": " Identification of F1 and F2 in Speech Using Modified Zero Frequency Filtering",
                                    "value": 1
                                },
                                {
                                    "name": " Phoneme-to-Audio Alignment with Recurrent Neural Networks for Speaking and Singing Voice",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Speech Signal Analysis and Representation  : I",
                            "children": [
                                {
                                    "name": " Estimating Articulatory Movements in Speech Production with Transformer Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Decomposition Based on a Hybrid Speech Model and Optimal Segmentation",
                                    "value": 1
                                },
                                {
                                    "name": " Dropout Regularization for Self-Supervised Learning of Transformer Encoder Speech Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Noise Robust Pitch Stylization Using Minimum Mean Absolute Error Criterion",
                                    "value": 1
                                },
                                {
                                    "name": " An Attribute-Aligned Strategy for Learning Speech Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Raw Speech-to-Articulatory Inversion by Temporal Filtering and Decimation",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Training of a DNN-Based Formant Tracker",
                                    "value": 1
                                },
                                {
                                    "name": " SUPERB: Speech Processing Universal PERformance Benchmark",
                                    "value": 1
                                },
                                {
                                    "name": " Synchronising Speech Segments with Musical Beats in Mandarin and English Singing",
                                    "value": 1
                                },
                                {
                                    "name": " FRILL: A Non-Semantic Speech Embedding for Mobile Devices",
                                    "value": 1
                                },
                                {
                                    "name": " Pitch Contour Separation from Overlapping Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Do Sound Event Representations Generalize to Other Audio Tasks? A Case Study in Audio Transfer Learning",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 17
                },
                {
                    "name": "Speaker Recognition",
                    "children": [
                        {
                            "name": "Speaker Recognition : Feature, Embedding and Neural Architecture for Speaker Recognition",
                            "children": [
                                {
                                    "name": " Adaptive Convolutional Neural Network for Text-Independent Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Bidirectional Multiscale Feature Aggregation for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Time Delay Neural Network Based Speaker Recognition with Convolutional Block and Feature Aggregation Methods",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Deep CNN Architectures with Variable-Length Training Samples for Text-Independent Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Binary Neural Network for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Mutual Information Enhanced Training for Speaker Embedding",
                                    "value": 1
                                },
                                {
                                    "name": " Y-Vector: Multiscale Waveform Encoder for Speaker Embedding",
                                    "value": 1
                                },
                                {
                                    "name": " Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        },
                        {
                            "name": "Speaker Recognition : Embedding and Network Architecture for Speaker Recognition",
                            "children": [
                                {
                                    "name": " Leveraging Speaker Attribute Information Using Multi Task Learning for Speaker Verification and Diarization",
                                    "value": 1
                                },
                                {
                                    "name": " Spine2Net: SpineNet with Res2Net and Time-Squeeze-and-Excitation Blocks for Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Embeddings by Modeling Channel-Wise Correlations",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Task Neural Network for Robust Multiple Speaker Embedding Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " ICSpk: Interpretable Complex Speaker Embedding Extractor from Raw Waveform",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        },
                        {
                            "name": "Speaker Recognition : Robust Speaker Recognition",
                            "children": [
                                {
                                    "name": " Unsupervised Bayesian Adaptation of PLDA for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " The DKU-Duke-Lenovo System Description for the Fearless Steps Challenge Phase III",
                                    "value": 1
                                },
                                {
                                    "name": " Improved Meta-Learning Training for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Variational Information Bottleneck Based Regularization for Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Out of a Hundred Trials, How Many Errors Does Your Speaker Verifier Make?",
                                    "value": 1
                                },
                                {
                                    "name": " SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System",
                                    "value": 1
                                },
                                {
                                    "name": " AntVoice Neural Speaker Embedding System for FFSVC 2020",
                                    "value": 1
                                },
                                {
                                    "name": " Gradient Regularization for Noise-Robust Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Feature CycleGANs: Speaker Identity Preserving Non-Parallel Microphone-Telephone Domain Adaptation for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Scaling Effect of Self-Supervised Speech Models",
                                    "value": 1
                                },
                                {
                                    "name": " Joint Feature Enhancement and Speaker Recognition with Multi-Objective Task-Oriented Network",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Level Transfer Learning from Near-Field to Far-Field Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Anonymisation Using the McAdams Coefficient",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        },
                        {
                            "name": "Speaker Recognition : Graph and End-to-End Learning for Speaker Recognition",
                            "children": [
                                {
                                    "name": " Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem",
                                    "value": 1
                                },
                                {
                                    "name": " Graph Attention Networks for Anti-Spoofing",
                                    "value": 1
                                },
                                {
                                    "name": " Log-Likelihood-Ratio Cost Function as Objective Loss for Speaker Verification Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Effective Phase Encoding for End-To-End Speaker Verification",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Speaker Recognition: Applications",
                            "children": [
                                {
                                    "name": " Graph-Based Label Propagation for Semi-Supervised Speaker Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " A Generative Model for Duration-Dependent Score Calibration",
                                    "value": 1
                                },
                                {
                                    "name": " Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Channel Speaker Verification for Single and Multi-Talker Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Chronological Self-Training for Real-Time Speaker Diarization",
                                    "value": 1
                                },
                                {
                                    "name": " Adaptive Margin Circle Loss for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Presentation Matters: Evaluating Speaker Identification Tasks",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Error Correction for Speaker Embedding Learning with Noisy Labels",
                                    "value": 1
                                },
                                {
                                    "name": " An Integrated Framework for Two-Pass Personalized Voice Trigger",
                                    "value": 1
                                },
                                {
                                    "name": " Masked Proxy Loss for Text-Independent Speaker Verification",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 42
                },
                {
                    "name": "Speech Enhancement",
                    "children": [
                        {
                            "name": "Speech Enhancement: Speech Enhancement and Intelligibility",
                            "children": [
                                {
                                    "name": " Funnel Deep Complex U-Net for Phase-Aware Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Temporal Convolutional Network with Frequency Dimension Adaptive Attention for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Perceptual Contributions of Vowels and Consonant-Vowel Transitions in Understanding Time-Compressed Mandarin Sentences",
                                    "value": 1
                                },
                                {
                                    "name": " Transfer Learning for Speech Intelligibility Improvement in Noisy Environments",
                                    "value": 1
                                },
                                {
                                    "name": " Comparison of Remote Experiments Using Crowdsourcing and Laboratory Experiments on Speech Intelligibility",
                                    "value": 1
                                },
                                {
                                    "name": " Know Your Enemy, Know Yourself: A Unified Two-Stage Framework for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Enhancement with Weakly Labelled Data from AudioSet",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Perceptual Quality by Phone-Fortified Perceptual Loss Using Wasserstein Distance for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " A Spectro-Temporal Glimpsing Index (STGI) for Speech Intelligibility Prediction",
                                    "value": 1
                                },
                                {
                                    "name": " Self-Supervised Learning Based Phone-Fortified Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Incorporating Embedding Vectors from a Human Mean-Opinion Score Prediction Model for Monaural Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Restoring Degraded Speech via a Modified Diffusion Model",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        },
                        {
                            "name": "Speech Enhancement: Multi-Channel Speech Enhancement and Hearing Aids",
                            "children": [
                                {
                                    "name": " LACOPE: Latency-Constrained Pitch Estimation for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation",
                                    "value": 1
                                },
                                {
                                    "name": " Microphone Array Generalization for Multichannel Narrowband Deep Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Multiple Sound Source Localization Based on Interchannel Phase Differences in All Frequencies with Spectral Masks",
                                    "value": 1
                                },
                                {
                                    "name": " Cancellation of Local Competing Speaker with Near-Field Localization for Distributed ad-hoc Sensor Network",
                                    "value": 1
                                },
                                {
                                    "name": " A Deep Learning Method to Multi-Channel Active Noise Control",
                                    "value": 1
                                },
                                {
                                    "name": " Clarity-2021 Challenges: Machine Learning Challenges for Advancing Hearing Aid Processing",
                                    "value": 1
                                },
                                {
                                    "name": " Optimising Hearing Aid Fittings for Speech in Noise with a Differentiable Hearing Loss Model",
                                    "value": 1
                                },
                                {
                                    "name": " Explaining Deep Learning Models for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Minimum-Norm Differential Beamforming for Linear Array with Directional Microphones",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        },
                        {
                            "name": "Speech Enhancement: Single-Channel Speech Enhancement",
                            "children": [
                                {
                                    "name": " Personalized Speech Enhancement Through Self-Supervised Data Augmentation and Purification",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Denoising with Auditory Models",
                                    "value": 1
                                },
                                {
                                    "name": " Human Listening and Live Captioning: Multi-Task Training for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Stage Progressive Speech Enhancement Network",
                                    "value": 1
                                },
                                {
                                    "name": " Single-Channel Speech Enhancement Using Learnable Loss Mixup",
                                    "value": 1
                                },
                                {
                                    "name": " A Maximum Likelihood Approach to SNR-Progressive Learning Using Generalized Gaussian Distribution for LSTM-Based Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Whisper Speech Enhancement Using Joint Variational Autoencoder for Improved Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " DEMUCS-Mobile : On-Device Lightweight Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Denoising Without Clean Training Data: A Noise2Noise Approach",
                                    "value": 1
                                },
                                {
                                    "name": " Improved Speech Enhancement Using a Complex-Domain GAN with Fused Time-Domain and Time-Frequency Domain Constraints",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Enhancement with Topology-Enhanced Generative Adversarial Networks (GANs)",
                                    "value": 1
                                },
                                {
                                    "name": " Learning Speech Structure to Improve Time-Frequency Masks",
                                    "value": 1
                                },
                                {
                                    "name": " SE-Conformer: Time-Domain Speech Enhancement Using Conformer",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        },
                        {
                            "name": "Speech Enhancement: Speech Enhancement and Coding",
                            "children": [
                                {
                                    "name": " End-to-End Optimized Multi-Stage Vector Quantization of Spectral Envelopes for Speech and Audio Coding",
                                    "value": 1
                                },
                                {
                                    "name": " Fusion-Net: Time-Frequency Information Fusion Y-Network for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " N-MTTL SI Model: Non-Intrusive Multi-Task Transfer Learning-Based Speech Intelligibility Prediction Model with Scenery Classification",
                                    "value": 1
                                }
                            ],
                            "value": 3
                        }
                    ],
                    "value": 39
                },
                {
                    "name": "Spoken Dialogue Systems",
                    "children": [
                        {
                            "name": "Spoken Dialogue Systems  : I",
                            "children": [
                                {
                                    "name": " User-Initiated Repetition-Based Recovery in Multi-Utterance Dialogue Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Self-Supervised Dialogue Learning for Spoken Conversational Question Answering",
                                    "value": 1
                                },
                                {
                                    "name": " Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking",
                                    "value": 1
                                },
                                {
                                    "name": " Dialogue Situation Recognition for Everyday Conversation Using Multimodal Information",
                                    "value": 1
                                },
                                {
                                    "name": " Neural Spoken-Response Generation Using Prosodic and Linguistic Context for Conversational Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Semantic Transportation Prototypical Network for Few-Shot Intent Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Domain-Specific Multi-Agent Dialog Policy Learning in Multi-Domain Task-Oriented Scenarios",
                                    "value": 1
                                },
                                {
                                    "name": " Leveraging ASR N-Best in Deep Entity Retrieval",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        },
                        {
                            "name": "Spoken Dialogue Systems : II",
                            "children": [
                                {
                                    "name": " Contextualized Attention-Based Knowledge Transfer for Spoken Conversational Question Answering",
                                    "value": 1
                                },
                                {
                                    "name": " Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks",
                                    "value": 1
                                },
                                {
                                    "name": " Causal Confusion Reduction for Robust Multi-Domain Dialogue Policy",
                                    "value": 1
                                },
                                {
                                    "name": " Timing Generating Networks: Neural Network Based Precise Turn-Taking Timing Prediction in Multiparty Conversation",
                                    "value": 1
                                },
                                {
                                    "name": " Human-to-Human Conversation Dataset for Learning Fine-Grained Turn-Taking Action",
                                    "value": 1
                                },
                                {
                                    "name": " PhonemeBERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript",
                                    "value": 1
                                },
                                {
                                    "name": " Joint Retrieval-Extraction Training for Evidence-Aware Dialog Response Selection",
                                    "value": 1
                                },
                                {
                                    "name": " Adapting Long Context NLM for ASR Rescoring in Conversational Agents",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        }
                    ],
                    "value": 16
                },
                {
                    "name": "Topics in ASR",
                    "children": [
                        {
                            "name": "Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR",
                            "children": [
                                {
                                    "name": " End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Acoustic Modelling Using Raw Source and Filter Components",
                                    "value": 1
                                },
                                {
                                    "name": " Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture",
                                    "value": 1
                                },
                                {
                                    "name": " IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Channel Transformer Transducer for Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios",
                                    "value": 1
                                },
                                {
                                    "name": " Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Rethinking Evaluation in ASR: Are Our Models Robust Enough?",
                                    "value": 1
                                },
                                {
                                    "name": " Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Topics in ASR :ASR Technologies and Systems",
                            "children": [
                                {
                                    "name": " Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw",
                                    "value": 1
                                },
                                {
                                    "name": " Aligned Contrastive Predictive Coding",
                                    "value": 1
                                },
                                {
                                    "name": " Neural Text Denormalization for Speech Transcripts",
                                    "value": 1
                                },
                                {
                                    "name": " Fearless Steps Challenge Phase 3(FSC P3): Advancing SLT for Unseen Channel and Mission Data Across NASA Apollo Audio",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Topics in ASR: Adaptation, Transfer Learning, Childrens Speech, and Low-Resource Settings",
                            "children": [
                                {
                                    "name": " Semantic Data Augmentation for End-to-End Mandarin Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Layer-Wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Low Resource German ASR with Untranscribed Data Spoken by Non-Native Children  INTERSPEECH 2021 Shared Task SPAPL System",
                                    "value": 1
                                },
                                {
                                    "name": " Robust Continuous On-Device Personalization for Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Normalization Using Joint Variational Autoencoder",
                                    "value": 1
                                },
                                {
                                    "name": " The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech",
                                    "value": 1
                                },
                                {
                                    "name": " On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Zero-Shot Cross-Lingual Phonetic Recognition with External Language Embedding",
                                    "value": 1
                                },
                                {
                                    "name": " Rapid Speaker Adaptation for Conformer Transducer: Attention and Bias Are All You Need",
                                    "value": 1
                                },
                                {
                                    "name": " Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Extending Pronunciation Dictionary with Automatically Detected Word Mispronunciations to Improve PAII\u2019s System for Interspeech 2021 Non-Native Child English Close Track ASR Challenge",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Topics in ASR : Miscellaneous",
                            "children": [
                                {
                                    "name": " Golos: Russian Dataset for Speech Research",
                                    "value": 1
                                },
                                {
                                    "name": " Radically Old Way of Computing Spectra: Applications in End-to-End ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Self-Supervised End-to-End ASR for Low Resource L2 Swedish",
                                    "value": 1
                                },
                                {
                                    "name": " SPGISpeech: 5,000 Hours of Transcribed Financial Audio for Fully Formatted End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " //LeBenchmark//: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        },
                        {
                            "name": "Topics in ASR : Language and Accent Recognition",
                            "children": [
                                {
                                    "name": " End-to-End Language Diarization for Bilingual Code-Switching Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Modeling and Training Strategies for Language Recognition Systems",
                                    "value": 1
                                },
                                {
                                    "name": " A Weight Moving Average Based Alternate Decoupled Learning Algorithm for Long-Tailed Language Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Exploring wav2vec 2.0 on Speaker Verification and Language Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Self-Supervised Phonotactic Representations for Language Identification",
                                    "value": 1
                                },
                                {
                                    "name": " E2E-Based Multi-Task Learning Approach to Joint Speech and Accent Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Excitation Source Feature Based Dialect Identification in Ao  A Low Resource Language",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        },
                        {
                            "name": "Topics in ASR : Low-Resource Speech Recognition",
                            "children": [
                                {
                                    "name": " Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Speech SimCLR: Combining Contrastive and Reconstruction Objective for Self-Supervised Speech Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language",
                                    "value": 1
                                },
                                {
                                    "name": " Analyzing Speaker Information in Self-Supervised Models to Improve Zero-Resource Speech Processing",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Neural-Based Graph Clustering for Variable-Length Speech Representation Discovery of Zero-Resource Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " Identifying Indicators of Vulnerability from Short Speech Segments Using Acoustic and Textual Features",
                                    "value": 1
                                },
                                {
                                    "name": " The Zero Resource Speech Challenge 2021: Spoken Language Modelling",
                                    "value": 1
                                },
                                {
                                    "name": " Zero-Shot Federated Learning with New Classes for Audio Classification",
                                    "value": 1
                                },
                                {
                                    "name": " AVLnet: Learning Audio-Visual Language Representations from Instructional Videos",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        },
                        {
                            "name": "Topics in ASR : Streaming for ASR/RNN Transducers",
                            "children": [
                                {
                                    "name": " Super-Human Performance in Online Low-Latency Recognition of Conversational Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Multiple Softmax Architecture for Streaming Multilingual End-to-End ASR Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion",
                                    "value": 1
                                },
                                {
                                    "name": " An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling",
                                    "value": 1
                                },
                                {
                                    "name": " Streaming Multi-Talker Speech Recognition with Joint Speaker Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Streaming End-to-End Speech Recognition for Hybrid RNN-T/Attention Architecture",
                                    "value": 1
                                },
                                {
                                    "name": " Improving RNN-T ASR Accuracy Using Context Audio",
                                    "value": 1
                                },
                                {
                                    "name": " HMM-Free Encoder Pre-Training for Streaming RNN Transducer",
                                    "value": 1
                                },
                                {
                                    "name": " Reducing Exposure Bias in Training Recurrent Neural Network Transducers",
                                    "value": 1
                                },
                                {
                                    "name": " Bridging the Gap Between Streaming and Non-Streaming ASR Systems by Distilling Ensembles of CTC and RNN-T Models",
                                    "value": 1
                                },
                                {
                                    "name": " Mixture Model Attention: Flexible Streaming and Non-Streaming Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Mode Transformer Transducer with Stochastic Future Context",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        },
                        {
                            "name": "Topics in ASR : Language and Lexical Modeling for ASR",
                            "children": [
                                {
                                    "name": " Semantic Distance: A New Metric for ASR Performance Analysis Towards Spoken Language Understanding",
                                    "value": 1
                                },
                                {
                                    "name": " A Light-Weight Contextual Spelling Correction Model for Customizing Transducer-Based Speech Recognition Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Incorporating External POS Tagger for Punctuation Restoration",
                                    "value": 1
                                },
                                {
                                    "name": " Phonetically Induced Subwords for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Revisiting Parity of Human vs. Machine Conversational Speech Transcription",
                                    "value": 1
                                },
                                {
                                    "name": " Lookup-Table Recurrent Language Models for Long Tail Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Token-Level Supervised Contrastive Learning for Punctuation Restoration",
                                    "value": 1
                                },
                                {
                                    "name": " BART Based Semantic Correction for Mandarin Automatic Speech Recognition System",
                                    "value": 1
                                },
                                {
                                    "name": " Class-Based Neural Network Language Model for Second-Pass Rescoring in ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Customization of Neural Transducers by Mitigating Acoustic Mismatch of Synthesized Audio",
                                    "value": 1
                                },
                                {
                                    "name": " A Discriminative Entity-Aware Language Model for Virtual Assistants",
                                    "value": 1
                                },
                                {
                                    "name": " Correcting Automated and Manual Speech Transcription Errors Using Warped Language Models",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        },
                        {
                            "name": "Topics in ASR : Neural Network Training Methods and Architectures for ASR",
                            "children": [
                                {
                                    "name": " Self-Paced Ensemble Learning for Speech and Audio Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Knowledge Distillation for Streaming Transformer\u2013Transducer",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Conditional Independence for Pretext Task Selection in Self-Supervised Speech Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating Methods to Improve Language Model Integration for Attention-Based Encoder-Decoder ASR Models",
                                    "value": 1
                                },
                                {
                                    "name": " Comparing CTC and LFMMI for Out-of-Domain Adaptation of wav2vec 2.0 Acoustic Model",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Topics in ASR : Linguistic Components in End-to-End ASR",
                            "children": [
                                {
                                    "name": " The CSTR System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept",
                                    "value": 1
                                },
                                {
                                    "name": " Modeling Dialectal Variation for Swiss German Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Out-of-Vocabulary Words Detection with Attention and CTC Alignments in an End-to-End ASR System",
                                    "value": 1
                                },
                                {
                                    "name": " Training Hybrid Models on Noisy Transliterated Transcripts for Code-Switched Speech Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Topics in ASR : Oriental Language Recognition",
                            "children": [
                                {
                                    "name": " Oriental Language Recognition (OLR) 2020: Summary and Analysis",
                                    "value": 1
                                },
                                {
                                    "name": " Language Recognition on Unknown Conditions: The LORIA-Inria-MULTISPEECH System for AP20-OLR Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Dynamic Multi-Scale Convolution for Dialect Identification",
                                    "value": 1
                                },
                                {
                                    "name": " An End-to-End Dialect Identification System with Transfer Learning from a Multilingual Automatic Speech Recognition Model",
                                    "value": 1
                                },
                                {
                                    "name": " Language Recognition Based on Unsupervised Pretrained Models",
                                    "value": 1
                                },
                                {
                                    "name": " Additive Phoneme-Aware Margin Softmax Loss for Language Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Topics in ASR : Automatic Speech Recognition in Air Traffic Management",
                            "children": [
                                {
                                    "name": " Towards an Accent-Robust Approach for ATC Communications Transcription",
                                    "value": 1
                                },
                                {
                                    "name": " Detecting English Speech in the Air Traffic Control Voice Communication",
                                    "value": 1
                                },
                                {
                                    "name": " Robust Command Recognition for Lithuanian Air Traffic Control Tower Utterances",
                                    "value": 1
                                },
                                {
                                    "name": " Contextual Semi-Supervised Learning: An Approach to Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Modeling the Effect of Military Oxygen Masks on Speech Characteristics",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Topics in ASR : Multi- and Cross-Lingual ASR, Other",
                            "children": [
                                {
                                    "name": " Cross-Domain Speech Recognition with Unsupervised Character-Level Distribution Matching",
                                    "value": 1
                                },
                                {
                                    "name": " Large-Scale Pre-Training of End-to-End Multi-Talker ASR for Meeting Transcription with Single Distant Microphone",
                                    "value": 1
                                },
                                {
                                    "name": " On Minimum Word Error Rate Training of the Hybrid Autoregressive Transducer",
                                    "value": 1
                                },
                                {
                                    "name": " Reducing Streaming ASR Model Delay with Self Alignment",
                                    "value": 1
                                },
                                {
                                    "name": " Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Knowledge Distillation Based Training of Universal ASR Source Models for Cross-Lingual Transfer",
                                    "value": 1
                                },
                                {
                                    "name": " Listen with Intent: Improving Speech Recognition with Audio-to-Intent Front-End",
                                    "value": 1
                                },
                                {
                                    "name": " Exploring Targeted Universal Adversarial Perturbations to End-to-End ASR Models",
                                    "value": 1
                                },
                                {
                                    "name": " Earnings-21: A Practical Benchmark for ASR in the Wild",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Multilingual Transformer Transducer Models by Reducing Language Confusions",
                                    "value": 1
                                },
                                {
                                    "name": " Arabic Code-Switching Speech Recognition Using Monolingual Data",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Topics in ASR : Robust and Far-Field ASR",
                            "children": [
                                {
                                    "name": " Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-Field Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " ETLT 2021: Shared Task on Automatic Speech Recognition for Non-Native Children\u2019s Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Learning to Rank Microphones for Distant Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Simulating Reading Mistakes for Child Speech Transformer-Based Phone Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        },
                        {
                            "name": "Topics in ASR : Search/Decoding Techniques and Confidence Measures for ASR",
                            "children": [
                                {
                                    "name": " FSR: Accelerating the Inference Process of Transducer-Based Models by Applying Fast-Skip Regularization",
                                    "value": 1
                                },
                                {
                                    "name": " LT-LM: A Novel Non-Autoregressive Language Model for Single-Shot Lattice Rescoring",
                                    "value": 1
                                },
                                {
                                    "name": " A Hybrid Seq-2-Seq ASR Design for On-Device and Server Applications",
                                    "value": 1
                                },
                                {
                                    "name": " VAD-Free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording",
                                    "value": 1
                                },
                                {
                                    "name": " WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Neural Network Calibration for E2E Speech Recognition System",
                                    "value": 1
                                },
                                {
                                    "name": " Residual Energy-Based Models for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction",
                                    "value": 1
                                },
                                {
                                    "name": " Insights on Neural Representations for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Sequence-Level Confidence Classifier for ASR Utterance Accuracy and Application to Acoustic Models",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Topics in ASR : OpenASR20 and Low Resource ASR Development",
                            "children": [
                                {
                                    "name": " OpenASR20: An Open Challenge for Automatic Speech Recognition of Conversational Telephone Speech in Low-Resource Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Multitask Adaptation with Lattice-Free MMI for Multi-Genre Speech Recognition of Low Resource Languages",
                                    "value": 1
                                },
                                {
                                    "name": " An Improved Wav2Vec 2.0 Pre-Training Approach Using Enhanced Local Dependency Modeling for Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Systems for Low-Resource Speech Recognition Tasks in Open Automatic Speech Recognition and Formosa Speech Recognition Challenges",
                                    "value": 1
                                },
                                {
                                    "name": " The TNT Team System Descriptions of Cantonese and Mongolian for IARPA OpenASR20",
                                    "value": 1
                                },
                                {
                                    "name": " Combining Hybrid and End-to-End Approaches for the OpenASR20 Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " One Size Does Not Fit All in Resource-Constrained ASR",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        },
                        {
                            "name": "Topics in ASR : Resource-Constrained ASR",
                            "children": [
                                {
                                    "name": " Compressing 1D Time-Channel Separable Convolutions Using Sparse Random Ternary Matrices",
                                    "value": 1
                                },
                                {
                                    "name": " Weakly Supervised Construction of ASR Systems from Massive Video Data",
                                    "value": 1
                                },
                                {
                                    "name": " Broadcasted Residual Learning for Efficient Keyword Spotting",
                                    "value": 1
                                },
                                {
                                    "name": " CoDERT: Distilling Encoder Representations with Co-Learning for Transducer-Based Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Extremely Low Footprint End-to-End ASR System for Smart Device",
                                    "value": 1
                                },
                                {
                                    "name": " Dissecting User-Perceived Latency of On-Device E2E Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Amortized Neural Networks for Low-Latency Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Tied & Reduced RNN-T Decoder",
                                    "value": 1
                                },
                                {
                                    "name": " PQK: Model Compression via Pruning, Quantization, and Knowledge Distillation",
                                    "value": 1
                                },
                                {
                                    "name": " Collaborative Training of Acoustic Encoders for Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " The Energy and Carbon Footprint of Training End-to-End Speech Recognizers",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        },
                        {
                            "name": "Topics in ASR : Speech Recognition of Atypical Speech",
                            "children": [
                                {
                                    "name": " Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating the Utility of Multimodal Conversational Technology and Audiovisual Analytic Measures for the Assessment and Monitoring of Amyotrophic Lateral Sclerosis at Scale",
                                    "value": 1
                                },
                                {
                                    "name": " Handling Acoustic Variation in Dysarthric Speech Recognition Systems Through Model Combination",
                                    "value": 1
                                },
                                {
                                    "name": " Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Speaking with a KN95 Face Mask: ASR Performance and Speaker Compensation",
                                    "value": 1
                                },
                                {
                                    "name": " Adversarial Data Augmentation for Disordered Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Learning Explicit Prosody Models and Deep Speaker Embeddings for Atypical Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Bayesian Parametric and Architectural Domain Adaptation of LF-MMI Trained TDNNs for Elderly and Dysarthric Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " A Voice-Activated Switch for Persons with Motor and Speech Impairments: Isolated-Vowel Spotting Using Neural Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Conformer Parrotron: A Faster and Stronger End-to-End Speech Conversion and Recognition Model for Atypical Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme-Level Pronunciation Features",
                                    "value": 1
                                },
                                {
                                    "name": " Comparing Supervised Models and Learned Speech Representations for Classifying Intelligibility of Disordered Speech on Selected Phrases",
                                    "value": 1
                                },
                                {
                                    "name": " Analysis and Tuning of a Voice Assistant System for Dysfluent Speech",
                                    "value": 1
                                }
                            ],
                            "value": 15
                        }
                    ],
                    "value": 163
                },
                {
                    "name": "Voice Activity Detection and Keyword Spotting",
                    "children": [
                        {
                            "name": "Voice Activity Detection and Keyword Spotting",
                            "children": [
                                {
                                    "name": " Attention-Based Cross-Modal Fusion for Audio-Visual Voice Activity Detection in Musical Video Streams",
                                    "value": 1
                                },
                                {
                                    "name": " Noise-Tolerant Self-Supervised Learning for Audio-Visual Voice Activity Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Noisy Student-Teacher Training for Robust Keyword Spotting",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Channel VAD for Transcription of Group Discussion",
                                    "value": 1
                                },
                                {
                                    "name": " Audio-Visual Information Fusion Using Cross-Modal Teacher-Student Learning for Voice Activity Detection in Realistic Environments",
                                    "value": 1
                                },
                                {
                                    "name": " Enrollment-Less Training for Personalized Voice Activity Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Voice Activity Detection for Live Speech of Baseball Game Based on Tandem Connection with Speech/Noise Separation Model",
                                    "value": 1
                                },
                                {
                                    "name": " FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Transformer-Based Open-Vocabulary Keyword Spotting with Location-Guided Local Attention",
                                    "value": 1
                                },
                                {
                                    "name": " Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation",
                                    "value": 1
                                },
                                {
                                    "name": " A Lightweight Framework for Online Voice Activity Detection in the Wild",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 11
                },
                {
                    "name": "Voice and Voicing",
                    "children": [
                        {
                            "name": "Voice and Voicing",
                            "children": [
                                {
                                    "name": " \u201cSee what I mean, huh?\u201d Evaluating Visual Inspection of F\u2080 Tracking in Nasal Grunts",
                                    "value": 1
                                },
                                {
                                    "name": " System Performance as a Function of Calibration Methods, Sample Size and Sampling Variability in Likelihood Ratio-Based Forensic Voice Comparison",
                                    "value": 1
                                },
                                {
                                    "name": " Voicing Assimilations by French Speakers of German in Stop-Fricative Sequences",
                                    "value": 1
                                },
                                {
                                    "name": " The Four-Way Classification of Stops with Voicing and Aspiration for Non-Native Speech Evaluation",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic and Prosodic Correlates of Emotions in Urdu Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Voicing Contrasts in the Singleton Stops of Palestinian Arabic: Production and Perception",
                                    "value": 1
                                },
                                {
                                    "name": " A Comparison of the Accuracy of Dissen and Keshet\u2019s (2016) DeepFormants and Traditional LPC Methods for Semi-Automatic Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " MAP Adaptation Characteristics in Forensic Long-Term Formant Analysis",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Linguistic Speaker Individuality of Long-Term Formant Distributions: Phonetic and Forensic Perspectives",
                                    "value": 1
                                },
                                {
                                    "name": " Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals",
                                    "value": 1
                                },
                                {
                                    "name": " Characterizing Voiced and Voiceless Nasals in Mizo",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 11
                },
                {
                    "name": "The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE)    COVID-19 Cough, COVID-19 Speech, Escalation    Primates",
                    "children": [
                        {
                            "name": "The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE)    COVID-19 Cough, COVID-19 Speech, Escalation    Primates",
                            "children": [
                                {
                                    "name": " The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation & Primates",
                                    "value": 1
                                },
                                {
                                    "name": " Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19",
                                    "value": 1
                                },
                                {
                                    "name": " The Phonetic Footprint of Covid-19?",
                                    "value": 1
                                },
                                {
                                    "name": " Transfer Learning and Data Augmentation Techniques to the COVID-19 Identification Tasks in ComParE 2021",
                                    "value": 1
                                },
                                {
                                    "name": " Visual Transformers for Primates Classification and Covid Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Deep-Learning-Based Central African Primate Species Classification with MixUp and SpecAugment",
                                    "value": 1
                                },
                                {
                                    "name": " A Deep and Recurrent Architecture for Primate Vocalization Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Introducing a Central African Primate Vocalisation Dataset for Automated Species Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Attentive Detection of the Spider Monkey Whinny in the (Actual) Wild",
                                    "value": 1
                                },
                                {
                                    "name": " Identifying Conflict Escalation and Primates by Using Ensemble X-Vectors and Fisher Vector Features",
                                    "value": 1
                                },
                                {
                                    "name": " Ensemble-Within-Ensemble Classification for Escalation Prediction from Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Analysis by Synthesis: Using an Expressive TTS Model as Feature Extractor for Paralinguistic Speech Classification",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 12
                },
                {
                    "name": "Survey Talk",
                    "children": [
                        {
                            "name": "Survey Talk : 1",
                            "children": [
                                {
                                    "name": " Towards Automatic Speech Recognition for People with Atypical Speech",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Survey Talk : 2",
                            "children": [
                                {
                                    "name": " Uncovering the Acoustic Cues of COVID-19 Infection",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Survey Talk : 3",
                            "children": [
                                {
                                    "name": " Learning Speech Models from Multi-Modal Data",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Survey Talk : 4",
                            "children": [
                                {
                                    "name": " Child Language Acquisition Studied with Wearables",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        }
                    ],
                    "value": 4
                },
                {
                    "name": "Speech Perception",
                    "children": [
                        {
                            "name": "Speech Perception  : I",
                            "children": [
                                {
                                    "name": " Prosodic Disambiguation Using Chironomic Stylization of Intonation with Native and Non-Native Speakers",
                                    "value": 1
                                },
                                {
                                    "name": " Variation in Perceptual Sensitivity and Compensation for Coarticulation Across Adult and Child Naturally-Produced and TTS Voices",
                                    "value": 1
                                },
                                {
                                    "name": " Extracting Different Levels of Speech Information from EEG Using an LSTM-Based Model",
                                    "value": 1
                                },
                                {
                                    "name": " Word Competition: An Entropy-Based Approach in the DIANA Model of Human Word Comprehension",
                                    "value": 1
                                },
                                {
                                    "name": " Time-to-Event Models for Analyzing Reaction Time Sequences",
                                    "value": 1
                                },
                                {
                                    "name": " Models of Reaction Times in Auditory Lexical Decision: RTonset versus RToffset",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Speech Perception : II",
                            "children": [
                                {
                                    "name": " Perception of Standard Arabic Synthetic Speech Rate",
                                    "value": 1
                                },
                                {
                                    "name": " The Influence of Parallel Processing on Illusory Vowels",
                                    "value": 1
                                },
                                {
                                    "name": " Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors",
                                    "value": 1
                                },
                                {
                                    "name": " SPEECHADJUSTER: A Tool for Investigating Listener Preferences and Speech Intelligibility",
                                    "value": 1
                                },
                                {
                                    "name": " VocalTurk: Exploring Feasibility of Crowdsourced Speaker Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Effects of Aging and Age-Related Hearing Loss on Talker Discrimination",
                                    "value": 1
                                },
                                {
                                    "name": " Relationships Between Perceptual Distinctiveness, Articulatory Complexity and Functional Load in Speech Communication",
                                    "value": 1
                                },
                                {
                                    "name": " Human Spoofing Detection Performance on Degraded Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Reliable Estimates of Interpretable Cue Effects with Active Learning in Psycholinguistic Research",
                                    "value": 1
                                },
                                {
                                    "name": " Towards the Explainability of Multimodal Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Primacy of Mouth over Eyes: Eye Movement Evidence from Audiovisual Mandarin Lexical Tones and Vowels",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating the Impact of Spectral and Temporal Degradation on End-to-End Automatic Speech Recognition Performance",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 18
                },
                {
                    "name": "Acoustic Event Detection and Acoustic Scene Classification",
                    "children": [
                        {
                            "name": "Acoustic Event Detection and Acoustic Scene Classification",
                            "children": [
                                {
                                    "name": " SpecMix : A Mixed Sample Data Augmentation Method for Training with Time-Frequency Domain Features",
                                    "value": 1
                                },
                                {
                                    "name": " SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification",
                                    "value": 1
                                },
                                {
                                    "name": " An Effective Mutual Mean Teaching Based Domain Adaptation Method for Sound Event Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Scene Classification Using Kervolution-Based SubSpectralNet",
                                    "value": 1
                                },
                                {
                                    "name": " Event Specific Attention for Polyphonic Sound Event Detection",
                                    "value": 1
                                },
                                {
                                    "name": " AST: Audio Spectrogram Transformer",
                                    "value": 1
                                },
                                {
                                    "name": " Shallow Convolution-Augmented Transformer with Differentiable Neural Computer for Low-Complexity Classification of Variable-Length Acoustic Scene",
                                    "value": 1
                                },
                                {
                                    "name": " An Evaluation of Data Augmentation Methods for Sound Scene Geotagging",
                                    "value": 1
                                },
                                {
                                    "name": " Optimizing Latency for Online Video Captioning Using Audio-Visual Transformers",
                                    "value": 1
                                },
                                {
                                    "name": " Variational Information Bottleneck for Effective Low-Resource Audio Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Weakly Supervised Sound Event Detection with Self-Supervised Auxiliary Tasks",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Event Detection with Classifier Chains",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 12
                },
                {
                    "name": "Diverse Modes of Speech Acquisition and Processing",
                    "children": [
                        {
                            "name": "Diverse Modes of Speech Acquisition and Processing",
                            "children": [
                                {
                                    "name": " Segment and Tone Production in Continuous Speech of Hearing and Hearing-Impaired Children",
                                    "value": 1
                                },
                                {
                                    "name": " Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing",
                                    "value": 1
                                },
                                {
                                    "name": " A Comparative Study of Different EMG Features for Acoustics-to-EMG Mapping",
                                    "value": 1
                                },
                                {
                                    "name": " Image-Based Assessment of Jaw Parameters and Jaw Kinematics for Articulatory Simulation: Preliminary Results",
                                    "value": 1
                                },
                                {
                                    "name": " An Attention Self-Supervised Contrastive Learning Based Three-Stage Model for Hand Shape Feature Representation in Cued Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Remote Smartphone-Based Speech Collection: Acceptance and Barriers in Individuals with Major Depressive Disorder",
                                    "value": 1
                                },
                                {
                                    "name": " An Automatic, Simple Ultrasound Biofeedback Parameter for Distinguishing Accurate and Misarticulated Rhotic Syllables",
                                    "value": 1
                                },
                                {
                                    "name": " Silent versus Modal Multi-Speaker Speech Recognition from Ultrasound and Video",
                                    "value": 1
                                },
                                {
                                    "name": " RaSSpeR: Radar-Based Silent Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating Speech Reconstruction for Laryngectomees for Silent Speech Interfaces",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        }
                    ],
                    "value": 10
                },
                {
                    "name": "Self-Supervision and Semi-Supervision for Neural ASR Training",
                    "children": [
                        {
                            "name": "Self-Supervision and Semi-Supervision for Neural ASR Training",
                            "children": [
                                {
                                    "name": " Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning",
                                    "value": 1
                                },
                                {
                                    "name": " wav2vec-C: A Self-Supervised Model for Speech Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " On the Learning Dynamics of Semi-Supervised Training for ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training",
                                    "value": 1
                                },
                                {
                                    "name": " Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models",
                                    "value": 1
                                },
                                {
                                    "name": " Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation",
                                    "value": 1
                                },
                                {
                                    "name": " slimIPL: Language-Model-Free Iterative Pseudo-Labeling",
                                    "value": 1
                                },
                                {
                                    "name": " Phonetically Motivated Self-Supervised Speech Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        }
                    ],
                    "value": 10
                },
                {
                    "name": "Spoken Language Processing",
                    "children": [
                        {
                            "name": "Spoken Language Processing  : I",
                            "children": [
                                {
                                    "name": " Speaker-Conversation Factorial Designs for Diarization Error Analysis",
                                    "value": 1
                                },
                                {
                                    "name": " SmallER: Scaling Neural Entity Resolution for Edge Devices",
                                    "value": 1
                                },
                                {
                                    "name": " Disfluency Detection with Unlabeled Data and Small BERT Models",
                                    "value": 1
                                },
                                {
                                    "name": " Discriminative Self-Training for Punctuation Prediction",
                                    "value": 1
                                },
                                {
                                    "name": " Zero-Shot Joint Modeling of Multiple Spoken-Text-Style Conversion Tasks Using Switching Tokens",
                                    "value": 1
                                },
                                {
                                    "name": " A Noise Robust Method for Word-Level Pronunciation Assessment",
                                    "value": 1
                                },
                                {
                                    "name": " Targeted Keyword Filtering for Accelerated Spoken Topic Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Multimodal Speech Summarization Through Semantic Concept Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Enhancing Semantic Understanding with Self-Supervised Methods for Abstractive Dialogue Summarization",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Transition Patterns in Three-Party Conversation: Evidence from English, Estonian and Swedish",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        },
                        {
                            "name": "Spoken Language Processing : II",
                            "children": [
                                {
                                    "name": " Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Lost in Interpreting: Speech Translation from Source or Interpreter?",
                                    "value": 1
                                },
                                {
                                    "name": " Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-Based Multimodal Fusion",
                                    "value": 1
                                },
                                {
                                    "name": " It\u2019s Not What You Said, it\u2019s How You Said it: Discriminative Perception of Speech as a Multichannel Communication System",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        }
                    ],
                    "value": 14
                },
                {
                    "name": "Voice Conversion and Adaptation",
                    "children": [
                        {
                            "name": "Voice Conversion and Adaptation : II",
                            "children": [
                                {
                                    "name": " Investigating Deep Neural Structures and their Interpretability in the Domain of Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-Stage Sequence-to-Sequence Training",
                                    "value": 1
                                },
                                {
                                    "name": " Adversarial Voice Conversion Against Neural Spoofing Detectors",
                                    "value": 1
                                },
                                {
                                    "name": " An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice Quality and Data Augmentation",
                                    "value": 1
                                },
                                {
                                    "name": " TVQVC: Transformer Based Vector Quantized Variational Autoencoder with CTC Loss for Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Enriching Source Style Transfer in Recognition-Synthesis Based Non-Parallel Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations",
                                    "value": 1
                                },
                                {
                                    "name": " An Exemplar Selection Algorithm for Native-Nonnative Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Adversarially Learning Disentangled Speech Representations for Robust Multi-Factor Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Many-to-Many Voice Conversion Based Feature Disentanglement Using Variational Autoencoder",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        },
                        {
                            "name": "Voice Conversion and Adaptation  : I",
                            "children": [
                                {
                                    "name": " CVC: Contrastive Learning for Non-Parallel Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " One-Shot Voice Conversion with Speaker-Agnostic StarGAN",
                                    "value": 1
                                },
                                {
                                    "name": " Fine-Tuning Pre-Trained Voice Conversion Model for Adding New Target Speakers with Limited Data",
                                    "value": 1
                                },
                                {
                                    "name": " VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-Shot Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " StarGANv2-VC: A Diverse, Unsupervised, Non-Parallel Framework for Natural-Sounding Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Normalization Driven Zero-Shot Multi-Speaker Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " StarGAN-VC+ASR: StarGAN-Based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Two-Pathway Style Embedding for Arbitrary Voice Conversion",
                                    "value": 1
                                },
                                {
                                    "name": " Non-Parallel Any-to-Many Voice Conversion by Replacing Speaker Statistics",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Lingual Voice Conversion with a Cycle Consistency Loss on Linguistic Representation",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Robustness of One-Shot Voice Conversion with Deep Discriminative Speaker Encoder",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 22
                },
                {
                    "name": "Privacy-Preserving Machine Learning for Audio    Speech Processing",
                    "children": [
                        {
                            "name": "Privacy-Preserving Machine Learning for Audio    Speech Processing",
                            "children": [
                                {
                                    "name": " Privacy-Preserving Voice Anti-Spoofing Using Secure Multi-Party Computation",
                                    "value": 1
                                },
                                {
                                    "name": " Configurable Privacy-Preserving Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Adjunct-Emeritus Distillation for Semi-Supervised Language Model Adaptation",
                                    "value": 1
                                },
                                {
                                    "name": " Communication-Efficient Agnostic Federated Averaging",
                                    "value": 1
                                },
                                {
                                    "name": " Privacy-Preserving Feature Extraction for Cloud-Based Wake Word Verification",
                                    "value": 1
                                },
                                {
                                    "name": " PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Continual Learning for Fake Audio Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Evaluating the Vulnerability of End-to-End Automatic Speech Recognition Models to Membership Inference Attacks",
                                    "value": 1
                                },
                                {
                                    "name": " SynthASR: Unlocking Synthetic Data for Speech Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        }
                    ],
                    "value": 9
                },
                {
                    "name": "The First DiCOVA Challenge",
                    "children": [
                        {
                            "name": "The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics",
                            "children": [
                                {
                                    "name": " DiCOVA Challenge: Dataset, Task, and Baseline System for COVID-19 Diagnosis Using Acoustics",
                                    "value": 1
                                },
                                {
                                    "name": " PANACEA Cough Sound-Based Diagnosis of COVID-19 for the DiCOVA 2021 Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Recognising Covid-19 from Coughing Using Ensembles of SVMs and LSTMs with Handcrafted and Deep Audio Features",
                                    "value": 1
                                },
                                {
                                    "name": " Detecting COVID-19 from Audio Recording of Coughs Using Random Forests and Support Vector Machines",
                                    "value": 1
                                },
                                {
                                    "name": " Diagnosis of COVID-19 Using Auditory Acoustic Cues",
                                    "value": 1
                                },
                                {
                                    "name": " Classification of COVID-19 from Cough Using Autoregressive Predictive Coding Pretraining and Spectral Data Augmentation",
                                    "value": 1
                                },
                                {
                                    "name": " The DiCOVA 2021 Challenge  An Encoder-Decoder Approach for COVID-19 Recognition from Coughing Audio",
                                    "value": 1
                                },
                                {
                                    "name": " COVID-19 Detection from Spectral Features on the DiCOVA Dataset",
                                    "value": 1
                                },
                                {
                                    "name": " Cough-Based COVID-19 Detection with Contextual Attention Convolutional Neural Networks and Gender Information",
                                    "value": 1
                                },
                                {
                                    "name": " Contrastive Learning of Cough Descriptors for Automatic COVID-19 Preliminary Diagnosis",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating Feature Selection and Explainability for COVID-19 Diagnostics from Cough Sounds",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 11
                },
                {
                    "name": "Show and Tell",
                    "children": [
                        {
                            "name": "Show and Tell : 1",
                            "children": [
                                {
                                    "name": " Application for Detecting Depression, Parkinson\u2019s Disease and Dysphonic Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Beey: More Than a Speech-to-Text Editor",
                                    "value": 1
                                },
                                {
                                    "name": " Downsizing of Vocal-Tract Models to Line up Variations and Reduce Manufacturing Costs",
                                    "value": 1
                                },
                                {
                                    "name": " ROXANNE Research Platform: Automate Criminal Investigations",
                                    "value": 1
                                },
                                {
                                    "name": " The LIUM Human Active Correction Platform for Speaker Diarization",
                                    "value": 1
                                },
                                {
                                    "name": " On-Device Streaming Transformer-Based End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Advanced Semi-Blind Speaker Extraction and Tracking Implemented in Experimental Device with Revolving Dense Microphone Array",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        },
                        {
                            "name": "Show and Tell : 2",
                            "children": [
                                {
                                    "name": " Multi-Speaker Emotional Text-to-Speech Synthesizer",
                                    "value": 1
                                },
                                {
                                    "name": " Live TV Subtitling Through Respeaking",
                                    "value": 1
                                },
                                {
                                    "name": " Autonomous Robot for Measuring Room Impulse Responses",
                                    "value": 1
                                },
                                {
                                    "name": " Expressive Robot Performance Based on Facial Motion Capture",
                                    "value": 1
                                },
                                {
                                    "name": " ThemePro 2.0: Showcasing the Role of Thematic Progression in Engaging Human-Computer Interaction",
                                    "value": 1
                                },
                                {
                                    "name": " Addressing Compliance in Call Centers with Entity Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " Audio Segmentation Based Conversational Silence Detection for Contact Center Calls",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        },
                        {
                            "name": "Show and Tell : 3",
                            "children": [
                                {
                                    "name": " MoM: Minutes of Meeting Bot",
                                    "value": 1
                                },
                                {
                                    "name": " Articulatory Data Recorder: A Framework for Real-Time Articulatory Data Recording",
                                    "value": 1
                                },
                                {
                                    "name": " The INGENIOUS Multilingual Operations App",
                                    "value": 1
                                },
                                {
                                    "name": " Digital Einstein Experience: Fast Text-to-Speech for Conversational AI",
                                    "value": 1
                                },
                                {
                                    "name": " Live Subtitling for BigBlueButton with Open-Source Software",
                                    "value": 1
                                },
                                {
                                    "name": " Expressive Latvian Speech Synthesis for Dialog Systems",
                                    "value": 1
                                },
                                {
                                    "name": " ViSTAFAE: A Visual Speech-Training Aid with Feedback of Articulatory Efforts",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        },
                        {
                            "name": "Show and Tell : 4",
                            "children": [
                                {
                                    "name": " Interactive and Real-Time Acoustic Measurement Tools for Speech Data Acquisition and Presentation: Application of an Extended Member of Time Stretched Pulses",
                                    "value": 1
                                },
                                {
                                    "name": " Save Your Voice: Voice Banking and TTS for Anyone",
                                    "value": 1
                                },
                                {
                                    "name": " NeMo (Inverse) Text Normalization: From Development to Production",
                                    "value": 1
                                },
                                {
                                    "name": " Lalilo: A Reading Assistant for Children Featuring Speech Recognition-Based Reading Mistake Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Radiology Report Editing Through Voice",
                                    "value": 1
                                },
                                {
                                    "name": " WittyKiddy: Multilingual Spoken Language Learning for Kids",
                                    "value": 1
                                },
                                {
                                    "name": " Duplex Conversation in Outbound Agent System",
                                    "value": 1
                                },
                                {
                                    "name": " Web Interface for Estimating Articulatory Movements in Speech Production from Acoustics and Text",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        }
                    ],
                    "value": 29
                },
                {
                    "name": "Keynote",
                    "children": [
                        {
                            "name": "Keynote : 1",
                            "children": [
                                {
                                    "name": " Forty Years of Speech and Language Processing: From Bayes Decision Rule to Deep Learning",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Keynote : 2",
                            "children": [
                                {
                                    "name": " Ethical and Technological Challenges of Conversational AI",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Keynote : 3",
                            "children": [
                                {
                                    "name": " Adaptive Listening to Everyday Soundscapes",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        },
                        {
                            "name": "Keynote : 4",
                            "children": [
                                {
                                    "name": " Language Modeling and Artificial Intelligence",
                                    "value": 1
                                }
                            ],
                            "value": 1
                        }
                    ],
                    "value": 4
                },
                {
                    "name": "Phonation and Voicing",
                    "children": [
                        {
                            "name": "Phonation and Voicing",
                            "children": [
                                {
                                    "name": " Voice Quality in Verbal Irony: Electroglottographic Analyses of Ironic Utterances in Standard Austrian German",
                                    "value": 1
                                },
                                {
                                    "name": " Synchronic Fortition in Five Romance Languages? A Large Corpus-Based Study of Word-Initial Devoicing",
                                    "value": 1
                                },
                                {
                                    "name": " Glottal Stops in Upper Sorbian: A Data-Driven Approach",
                                    "value": 1
                                },
                                {
                                    "name": " Cue Interaction in the Perception of Prosodic Prominence: The Role of Voice Quality",
                                    "value": 1
                                },
                                {
                                    "name": " Glottal Sounds in Korebaju",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Classification of Phonation Types in Spontaneous Speech: Towards a New Workflow for the Characterization of Speakers\u2019 Voice Quality",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        }
                    ],
                    "value": 6
                },
                {
                    "name": "Health and Affect",
                    "children": [
                        {
                            "name": "Health and Affect  : I",
                            "children": [
                                {
                                    "name": " Measuring Voice Quality Parameters After Speaker Pseudonymization",
                                    "value": 1
                                },
                                {
                                    "name": " Audio-Visual Recognition of Emotional Engagement of People with Dementia",
                                    "value": 1
                                },
                                {
                                    "name": " Speaking Corona? Human and Machine Recognition of COVID-19 from Voice",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic-Prosodic, Lexical and Demographic Cues to Persuasiveness in Competitive Debate Speeches",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Health and Affect : II",
                            "children": [
                                {
                                    "name": " Automatic Speech Recognition Systems Errors for Objective Sleepiness Detection Through Voice",
                                    "value": 1
                                },
                                {
                                    "name": " Robust Laughter Detection in Noisy Environments",
                                    "value": 1
                                },
                                {
                                    "name": " Impact of Emotional State on Estimation of Willingness to Buy from Advertising Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Stacked Recurrent Neural Networks for Speech-Based Inference of Attachment Condition in School Age Children",
                                    "value": 1
                                },
                                {
                                    "name": " Language or Paralanguage, This is the Problem: Comparing Depressed and Non-Depressed Speakers Through the Analysis of Gated Multimodal Units",
                                    "value": 1
                                },
                                {
                                    "name": " Emotion Carrier Recognition from Personal Narratives",
                                    "value": 1
                                },
                                {
                                    "name": " Non-Verbal Vocalisation and Laughter Detection Using Sequence-to-Sequence Models and Multi-Label Training",
                                    "value": 1
                                },
                                {
                                    "name": " TDCA-Net: Time-Domain Channel Attention Network for Depression Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Visual Speech for Obstructive Sleep Apnea Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Analysis of Contextual Voice Changes in Remote Meetings",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Based Depression Severity Level Classification Using a Multi-Stage Dilated CNN-LSTM Model",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 15
                },
                {
                    "name": "Source Separation, Dereverberation and Echo Cancellation",
                    "children": [
                        {
                            "name": "Source Separation, Dereverberation and Echo Cancellation",
                            "children": [
                                {
                                    "name": " Multi-Stream Gated and Pyramidal Temporal Convolutional Neural Networks for Audio-Visual Speech Separation in Multi-Talker Environments",
                                    "value": 1
                                },
                                {
                                    "name": " TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation",
                                    "value": 1
                                },
                                {
                                    "name": " Residual Echo and Noise Cancellation with Feature Attention Module and Multi-Domain Loss Function",
                                    "value": 1
                                },
                                {
                                    "name": " MIMO Self-Attentive RNN Beamformer for Multi-Speaker Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Personalized PercepNet: Real-Time, Low-Complexity Target Voice Separation and Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Scene-Agnostic Multi-Microphone Speech Dereverberation",
                                    "value": 1
                                },
                                {
                                    "name": " Manifold-Aware Deep Clustering: Maximizing Angles Between Embedding Vectors Based on Regular Simplex",
                                    "value": 1
                                },
                                {
                                    "name": " A Deep Learning Approach to Multi-Channel and Multi-Microphone Acoustic Echo Cancellation",
                                    "value": 1
                                },
                                {
                                    "name": " Joint Online Multichannel Acoustic Echo Cancellation, Speech Dereverberation and Source Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Should We Always Separate?: Switching Between Enhanced and Observed Signals for Overlapping Speech Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        }
                    ],
                    "value": 10
                },
                {
                    "name": "Spoken Language Understanding",
                    "children": [
                        {
                            "name": "Spoken Language Understanding  : I",
                            "children": [
                                {
                                    "name": " Data Augmentation for Spoken Language Understanding via Pretrained Language Models",
                                    "value": 1
                                },
                                {
                                    "name": " FANS: Fusing ASR and NLU for On-Device SLU",
                                    "value": 1
                                },
                                {
                                    "name": " Sequential End-to-End Intent and Slot Label Classification and Localization",
                                    "value": 1
                                },
                                {
                                    "name": " DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants",
                                    "value": 1
                                },
                                {
                                    "name": " A Context-Aware Hierarchical BERT Fusion Network for Multi-Turn Dialog Act Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Pre-Training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Predicting Temporal Performance Drop of Deployed Production Spoken Language Understanding Models",
                                    "value": 1
                                },
                                {
                                    "name": " Integrating Dialog History into End-to-End Spoken Language Understanding Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking",
                                    "value": 1
                                },
                                {
                                    "name": " Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        },
                        {
                            "name": "Spoken Language Understanding : II",
                            "children": [
                                {
                                    "name": " Intent Detection and Slot Filling for Vietnamese",
                                    "value": 1
                                },
                                {
                                    "name": " Augmenting Slot Values and Contexts for Spoken Language Understanding with Pretrained Models",
                                    "value": 1
                                },
                                {
                                    "name": " The Impact of Intent Distribution Mismatch on Semi-Supervised Spoken Language Understanding",
                                    "value": 1
                                },
                                {
                                    "name": " Knowledge Distillation from BERT Transformer to Speech Transformer for Intent Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-Trained DNN-HMM-Based Acoustic-Phonetic Model",
                                    "value": 1
                                },
                                {
                                    "name": " Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Cross-Lingual Spoken Language Understanding Model with Multilingual Pretraining",
                                    "value": 1
                                },
                                {
                                    "name": " Factorization-Aware Training of Transformers for Natural Language Understanding on the Edge",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Spoken Language Understanding for Generalized Voice Assistants",
                                    "value": 1
                                },
                                {
                                    "name": " Bi-Directional Joint Neural Networks for Intent Classification and Slot Filling",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        }
                    ],
                    "value": 20
                },
                {
                    "name": "Voice Quality Characterization for Clinical Voice Assessment",
                    "children": [
                        {
                            "name": "Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception",
                            "children": [
                                {
                                    "name": " Optimizing an Automatic Creaky Voice Detection Method for Australian English Speaking Females",
                                    "value": 1
                                },
                                {
                                    "name": " A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating Voice Function Characteristics of Greek Speakers with Hearing Loss Using Automatic Glottal Source Feature Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " Automated Detection of Voice Disorder in the Saarbr\u00fccken Voice Database: Effects of Pathology Subset and Audio Materials",
                                    "value": 1
                                },
                                {
                                    "name": " Accelerometer-Based Measurements of Voice Quality in Children During Semi-Occluded Vocal Tract Exercise with a Narrow Straw in Air",
                                    "value": 1
                                },
                                {
                                    "name": " Articulatory Coordination for Speech Motor Tracking in Huntington Disease",
                                    "value": 1
                                },
                                {
                                    "name": " Modeling Dysphonia Severity as a Function of Roughness and Breathiness Ratings in the GRBAS Scale",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        }
                    ],
                    "value": 7
                },
                {
                    "name": "Phonetics",
                    "children": [
                        {
                            "name": "Phonetics  : I",
                            "children": [
                                {
                                    "name": " Prosodic Accommodation in Face-to-Face and Telephone Dialogues",
                                    "value": 1
                                },
                                {
                                    "name": " Dialect Features in Heterogeneous and Homogeneous Gheg Speaking Communities",
                                    "value": 1
                                },
                                {
                                    "name": " An Exploration of the Acoustic Space of Rhotics and Laterals in Ruruuli",
                                    "value": 1
                                },
                                {
                                    "name": " Domain-Initial Strengthening in Turkish: Acoustic Cues to Prosodic Hierarchy in Stop Consonants",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        },
                        {
                            "name": "Phonetics : II",
                            "children": [
                                {
                                    "name": " Leveraging Real-Time MRI for Illuminating Linguistic Velum Action",
                                    "value": 1
                                },
                                {
                                    "name": " Segmental Alignment of English Syllables with Singleton and Cluster Onsets",
                                    "value": 1
                                },
                                {
                                    "name": " Exploration of Welsh English Pre-Aspiration: How Wide-Spread is it?",
                                    "value": 1
                                },
                                {
                                    "name": " Revisiting Recall Effects of Filler Particles in German and English",
                                    "value": 1
                                },
                                {
                                    "name": " How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements",
                                    "value": 1
                                },
                                {
                                    "name": " A Cross-Dialectal Comparison of Apical Vowels in Beijing Mandarin, Northeastern Mandarin and Southwestern Mandarin: An EMA and Ultrasound Study",
                                    "value": 1
                                },
                                {
                                    "name": " Dissecting the Aero-Acoustic Parameters of Open Articulatory Transitions",
                                    "value": 1
                                },
                                {
                                    "name": " Quantifying Vocal Tract Shape Variation and its Acoustic Impact: A Geometric Morphometric Approach",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Perception and Loanword Adaptations: The Case of Copy-Vowel Epenthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Speakers Coarticulate Less When Facing Real and Imagined Communicative Difficulties: An Analysis of Read and Spontaneous Speech from the LUCID Corpus",
                                    "value": 1
                                },
                                {
                                    "name": " Developmental Changes of Vowel Acoustics in Adolescents",
                                    "value": 1
                                },
                                {
                                    "name": " Context and Co-Text Influence on the Accuracy Production of Italian L2 Non-Native Sounds",
                                    "value": 1
                                },
                                {
                                    "name": " A New Vowel Normalization for Sociophonetics",
                                    "value": 1
                                },
                                {
                                    "name": " The Pacific Expansion: Optimizing Phonetic Transcription of Archival Corpora",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        }
                    ],
                    "value": 18
                },
                {
                    "name": "Target Speaker Detection, Localization and Separation",
                    "children": [
                        {
                            "name": "Target Speaker Detection, Localization and Separation",
                            "children": [
                                {
                                    "name": " Auxiliary Loss Function for Target Speech Extraction and Recognition with Weak Supervision Based on Speaker Characteristics",
                                    "value": 1
                                },
                                {
                                    "name": " Universal Speaker Extraction in the Presence and Absence of Target Speakers for Speech of One and Two Talkers",
                                    "value": 1
                                },
                                {
                                    "name": " Using X-Vectors for Speech Activity Detection in Broadcast Streams",
                                    "value": 1
                                },
                                {
                                    "name": " Time Delay Estimation for Speaker Localization Using CNN-Based Parametrized GCC-PHAT Features",
                                    "value": 1
                                },
                                {
                                    "name": " Real-Time Speaker Counting in a Cocktail Party Scenario Using Attention-Guided Convolutional Neural Network",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        }
                    ],
                    "value": 5
                },
                {
                    "name": "Speech Coding and Privacy",
                    "children": [
                        {
                            "name": "Speech Coding and Privacy",
                            "children": [
                                {
                                    "name": " NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling",
                                    "value": 1
                                },
                                {
                                    "name": " QISTA-Net-Audio: Audio Super-Resolution via Non-Convex \u2113,,q,,-Norm Minimization",
                                    "value": 1
                                },
                                {
                                    "name": " X-net: A Joint Scale Down and Scale Up Method for Voice Call",
                                    "value": 1
                                },
                                {
                                    "name": " WSRGlow: A Glow-Based Waveform Generative Model for Audio Super-Resolution",
                                    "value": 1
                                },
                                {
                                    "name": " Half-Truth: A Partially Fake Audio Detection Dataset",
                                    "value": 1
                                },
                                {
                                    "name": " Data Quality as Predictor of Voice Anti-Spoofing Generalization",
                                    "value": 1
                                },
                                {
                                    "name": " Coded Speech Enhancement Using Neural Network-Based Vector-Quantized Residual Features",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Channel Opus Compression for Far-Field Automatic Speech Recognition with a Fixed Bitrate Budget",
                                    "value": 1
                                },
                                {
                                    "name": " Effects of Prosodic Variations on Accidental Triggers of a Commercial Voice Assistant",
                                    "value": 1
                                },
                                {
                                    "name": " Improving the Expressiveness of Neural Vocoding with Non-Affine Normalizing Flows",
                                    "value": 1
                                },
                                {
                                    "name": " Voice Privacy Through x-Vector and CycleGAN-Based Anonymization",
                                    "value": 1
                                },
                                {
                                    "name": " A Two-Stage Approach to Speech Bandwidth Extension",
                                    "value": 1
                                },
                                {
                                    "name": " Development of a Psychoacoustic Loss Function for the Deep Neural Network\t(DNN)-Based Speech Coder",
                                    "value": 1
                                },
                                {
                                    "name": " Protecting Gender and Identity with Disentangled Speech Representations",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        }
                    ],
                    "value": 14
                },
                {
                    "name": "Speech Enhancement: ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing",
                    "children": [
                        {
                            "name": "Speech Enhancement: ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing",
                            "children": [
                                {
                                    "name": " A Causal U-Net Based Neural Beamforming Network for Real-Time Multi-Channel Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " A Partitioned-Block Frequency-Domain Adaptive Kalman Filter for Stereophonic Acoustic Echo Cancellation",
                                    "value": 1
                                },
                                {
                                    "name": " Real-Time Independent Vector Analysis Using Semi-Supervised Nonnegative Matrix Factorization as a Source Model",
                                    "value": 1
                                },
                                {
                                    "name": " Improving Channel Decorrelation for Multi-Channel Target Speech Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " Inplace Gated Convolutional Recurrent Neural Network for Dual-Channel Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " SRIB-LEAP Submission to Far-Field Multi-Channel Speech Enhancement Challenge for Video Conferencing",
                                    "value": 1
                                },
                                {
                                    "name": " Real-Time Multi-Channel Speech Enhancement Based on Neural Network Masking with Attention Model",
                                    "value": 1
                                }
                            ],
                            "value": 7
                        }
                    ],
                    "value": 7
                },
                {
                    "name": "Language Modeling and Text-Based Innovations for ASR",
                    "children": [
                        {
                            "name": "Language Modeling and Text-Based Innovations for ASR",
                            "children": [
                                {
                                    "name": " BERT-Based Semantic Model for Rescoring N-Best Speech Recognition List",
                                    "value": 1
                                },
                                {
                                    "name": " Text Augmentation for Language Models in High Error Recognition Scenario",
                                    "value": 1
                                },
                                {
                                    "name": " On Sampling-Based Training Criteria for Neural Language Modeling",
                                    "value": 1
                                },
                                {
                                    "name": " Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        }
                    ],
                    "value": 4
                },
                {
                    "name": "Speaker, Language, and Privacy",
                    "children": [
                        {
                            "name": "Speaker, Language, and Privacy",
                            "children": [
                                {
                                    "name": " Using Games to Augment Corpora for Language Recognition and Confusability",
                                    "value": 1
                                },
                                {
                                    "name": " Fair Voice Biometrics: Impact of Demographic Imbalance on Group Fairness in Speaker Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Knowledge Distillation from Multi-Modality to Single-Modality for Person Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Adversarial Disentanglement of Speaker Representation for Attribute-Driven Privacy Preservation",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        }
                    ],
                    "value": 4
                },
                {
                    "name": "Assessment of Pathological Speech and Language",
                    "children": [
                        {
                            "name": "Assessment of Pathological Speech and Language  : I",
                            "children": [
                                {
                                    "name": " Automatically Detecting Errors and Disfluencies in Read Speech to Predict Cognitive Impairment in People with Parkinson\u2019s Disease",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Extraction of Speech Rhythm Descriptors for Speech Intelligibility Assessment in the Context of Head and Neck Cancers",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Disorder Classification Using Extended Factorized Hierarchical Variational Auto-Encoders",
                                    "value": 1
                                },
                                {
                                    "name": " The Impact of Forced-Alignment Errors on Automatic Pronunciation Evaluation",
                                    "value": 1
                                },
                                {
                                    "name": " Late Fusion of the Available Lexicon and Raw Waveform-Based Acoustic Modeling for Depression and Dementia Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Neural Speaker Embeddings for Ultrasound-Based Silent Speech Interfaces",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        },
                        {
                            "name": "Assessment of Pathological Speech and Language : II",
                            "children": [
                                {
                                    "name": " Speech Intelligibility of Dysarthric Speech: Human Scores and Acoustic-Phonetic Features",
                                    "value": 1
                                },
                                {
                                    "name": " Analyzing Short Term Dynamic Speech Features for Understanding Behavioral Traits of Children with Autism Spectrum Disorder",
                                    "value": 1
                                },
                                {
                                    "name": " Vocalization Recognition of People with Profound Intellectual and Multiple Disabilities (PIMD) Using Machine Learning Algorithms",
                                    "value": 1
                                },
                                {
                                    "name": " Phonetic Complexity, Speech Accuracy and Intelligibility Assessment of Italian Dysarthric Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Detection of Consonant Errors in Disordered Speech Based on Consonant-Vowel Segment Embedding",
                                    "value": 1
                                },
                                {
                                    "name": " Assessing Posterior-Based Mispronunciation Detection on Field-Collected Recordings from Child Speech Therapy Sessions",
                                    "value": 1
                                },
                                {
                                    "name": " Identifying Cognitive Impairment Using Sentence Representation Vectors",
                                    "value": 1
                                },
                                {
                                    "name": " Parental Spoken Scaffolding and Narrative Skills in Crowd-Sourced Storytelling Samples of Young Children",
                                    "value": 1
                                },
                                {
                                    "name": " Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Domain Adaptation for Dysarthric Speech Detection via Domain Adversarial Training and Mutual Information Minimization",
                                    "value": 1
                                },
                                {
                                    "name": " Source and Vocal Tract Cues for Speech-Based Classification of Patients with Parkinson\u2019s Disease and Healthy Subjects",
                                    "value": 1
                                },
                                {
                                    "name": " CLAC: A Speech Corpus of Healthy English Speakers",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 18
                },
                {
                    "name": "Communication and Interaction, Multimodality",
                    "children": [
                        {
                            "name": "Communication and Interaction, Multimodality",
                            "children": [
                                {
                                    "name": " Cross-Modal Learning for Audio-Visual Video Parsing",
                                    "value": 1
                                },
                                {
                                    "name": " A Psychology-Driven Computational Analysis of Political Interviews",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Emotion Recognition Based on Attention Weight Correction Using Word-Level Confidence Measure",
                                    "value": 1
                                },
                                {
                                    "name": " Effects of Voice Type and Task on L2 Learners\u2019 Awareness of Pronunciation Errors",
                                    "value": 1
                                },
                                {
                                    "name": " Lexical Entrainment and Intra-Speaker Variability in Cooperative Dialogues",
                                    "value": 1
                                },
                                {
                                    "name": " Detecting Alzheimer\u2019s Disease Using Interactional and Acoustic Features from Spontaneous Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Investigating the Interplay Between Affective, Phonatory and Motoric Subsystems in Autism Spectrum Disorder Using a Multimodal Dialogue Agent",
                                    "value": 1
                                },
                                {
                                    "name": " Analysis of Eye Gaze Reasons and Gaze Aversions During Three-Party Conversations",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        }
                    ],
                    "value": 8
                },
                {
                    "name": "Novel Neural Network Architectures for ASR",
                    "children": [
                        {
                            "name": "Novel Neural Network Architectures for ASR",
                            "children": [
                                {
                                    "name": " Dynamic Encoder Transducer: A Flexible Solution for Trading Off Accuracy for Latency",
                                    "value": 1
                                },
                                {
                                    "name": " Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Librispeech Transducer Model with Internal Language Model Prior Correction",
                                    "value": 1
                                },
                                {
                                    "name": " A Deliberation-Based Joint Acoustic and Text Decoder",
                                    "value": 1
                                },
                                {
                                    "name": " On the Limit of English Conversational Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Deformable TDNN with Adaptive Receptive Fields for Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Transformer-Based End-to-End Speech Recognition with Residual Gaussian-Based Self-Attention",
                                    "value": 1
                                },
                                {
                                    "name": " SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts",
                                    "value": 1
                                },
                                {
                                    "name": " Online Compressive Transformer for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " End to End Transformer-Based Contextual Speech Recognition Based on Pointer Network",
                                    "value": 1
                                },
                                {
                                    "name": " A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Advanced Long-Context End-to-End Speech Recognition Using Context-Expanded Transformers",
                                    "value": 1
                                },
                                {
                                    "name": " Transformer-Based ASR Incorporating Time-Reduction Layer and Fine-Tuning with Self-Knowledge Distillation",
                                    "value": 1
                                },
                                {
                                    "name": " Flexi-Transducer: Optimizing Latency, Accuracy and Compute for Multi-Domain On-Device Scenarios",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        }
                    ],
                    "value": 14
                },
                {
                    "name": "Speech Localization, Enhancement, and Quality Assessment",
                    "children": [
                        {
                            "name": "Speech Localization, Enhancement, and Quality Assessment",
                            "children": [
                                {
                                    "name": " Difference in Perceived Speech Signal Quality Assessment Among Monolingual and Bilingual Teenage Students",
                                    "value": 1
                                },
                                {
                                    "name": " PILOT: Introducing Transformers for Probabilistic Sound Event Localization",
                                    "value": 1
                                },
                                {
                                    "name": " Sound Source Localization with Majorization Minimization",
                                    "value": 1
                                },
                                {
                                    "name": " NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets",
                                    "value": 1
                                },
                                {
                                    "name": " Subjective Evaluation of Noise Suppression Algorithms in Crowdsourcing",
                                    "value": 1
                                },
                                {
                                    "name": " Reliable Intensity Vector Selection for Multi-Source Direction-of-Arrival Estimation Using a Single Acoustic Vector Sensor",
                                    "value": 1
                                },
                                {
                                    "name": " MetricNet: Towards Improved Modeling For Non-Intrusive Speech Quality Assessment",
                                    "value": 1
                                },
                                {
                                    "name": " CNN-Based Processing of Acoustic and Radio Frequency Signals for Speaker Localization from MAVs",
                                    "value": 1
                                },
                                {
                                    "name": " Assessment of von Mises-Bernoulli Deep Neural Network in Sound Source Localization",
                                    "value": 1
                                },
                                {
                                    "name": " Feature Fusion by Attention Networks for Robust DOA Estimation",
                                    "value": 1
                                },
                                {
                                    "name": " Far-Field Speaker Localization and Adaptive GLMB Tracking",
                                    "value": 1
                                },
                                {
                                    "name": " On the Design of Deep Priors for Unsupervised Audio Restoration",
                                    "value": 1
                                },
                                {
                                    "name": " Cram\u00e9r-Rao Lower Bound for DOA Estimation with an Array of Directional Microphones in Reverberant Environments",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "Spoken Machine Translation",
                    "children": [
                        {
                            "name": "Spoken Machine Translation",
                            "children": [
                                {
                                    "name": " SpecRec: An Alternative Solution for Improving End-to-End Speech-to-Text Translation via Spectrogram Reconstruction",
                                    "value": 1
                                },
                                {
                                    "name": " Subtitle Translation as Markup Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Large-Scale Self- and Semi-Supervised Learning for Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " CoVoST 2 and Massively Multilingual Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " AlloST: Low-Resource Speech Translation Without Source Transcription",
                                    "value": 1
                                },
                                {
                                    "name": " Weakly-Supervised Speech-to-Text Mapping with Visually Connected Non-Parallel Speech-Text Data Using Cyclic Partially-Aligned Transformer",
                                    "value": 1
                                },
                                {
                                    "name": " Transcribing Paralinguistic Acoustic Cues to Target Language Text in Transformer-Based Speech-to-Text Translation",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Speech Translation via Cross-Modal Progressive Training",
                                    "value": 1
                                },
                                {
                                    "name": " ASR Posterior-Based Loss for Multi-Task End-to-End Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Towards Simultaneous Machine Interpretation",
                                    "value": 1
                                },
                                {
                                    "name": " Lexical Modeling of ASR Errors for Robust Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Effects of Feature Scaling and Fusion on Sign Language Translation",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "SdSV Challenge 2021",
                    "children": [
                        {
                            "name": "SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification",
                            "children": [
                                {
                                    "name": " The ID R&D System Description for Short-Duration Speaker Verification Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " Integrating Frequency Translational Invariance in TDNNs and Frequency Positional Information in 2D ResNets to Enhance Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " SdSVC Challenge 2021: Tips and Tricks to Boost the Short-Duration Speaker Verification System Performance",
                                    "value": 1
                                },
                                {
                                    "name": " Team02 Text-Independent Speaker Verification System for SdSV Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " Our Learned Lessons from Cross-Lingual Speaker Verification: The CRMI-DKU System Description for the Short-Duration Speaker Verification Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " Investigation of IMU&Elevoc Submission for the Short-Duration Speaker Verification Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " The Sogou System for Short-Duration Speaker Verification Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " The SJTU System for Short-Duration Speaker Verification Challenge 2021",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        }
                    ],
                    "value": 8
                },
                {
                    "name": "Speech and Audio Analysis",
                    "children": [
                        {
                            "name": "Speech and Audio Analysis",
                            "children": [
                                {
                                    "name": " Extending the Fullband E-Model Towards Background Noise, Bursty Packet Loss, and Conversational Degradations",
                                    "value": 1
                                },
                                {
                                    "name": " ORCA-SLANG: An Automatic Multi-Stage Semi-Supervised Deep Learning Framework for Large-Scale Killer Whale Call Type Identification",
                                    "value": 1
                                },
                                {
                                    "name": " Audiovisual Transfer Learning for Audio Tagging and Sound Event Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Non-Intrusive Speech Quality Assessment with Transfer Learning and Subject-Specific Scaling",
                                    "value": 1
                                },
                                {
                                    "name": " Audio Retrieval with Natural Language Queries",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        }
                    ],
                    "value": 5
                },
                {
                    "name": "Cross/Multi-Lingual and Code-Switched ASR",
                    "children": [
                        {
                            "name": "Cross/Multi-Lingual and Code-Switched ASR",
                            "children": [
                                {
                                    "name": " Bootstrap an End-to-End ASR System by Multilingual Training, Transfer Learning, Text-to-Text Mapping and Synthetic Audio",
                                    "value": 1
                                },
                                {
                                    "name": " Efficient Weight Factorization for Multilingual Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Unsupervised Cross-Lingual Representation Learning for Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Language and Speaker-Independent Feature Transformation for End-to-End Multilingual Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Using Large Self-Supervised Models for Low-Resource Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Dual Script E2E Framework for Multilingual and Code-Switching ASR",
                                    "value": 1
                                },
                                {
                                    "name": " MUCS 2021: Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " SRI-B End-to-End System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
                                    "value": 1
                                },
                                {
                                    "name": " Hierarchical Phone Recognition with Compositional Phonetics",
                                    "value": 1
                                },
                                {
                                    "name": " Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Differentiable Allophone Graphs for Language-Universal Speech Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 12
                },
                {
                    "name": "Neural Network Training Methods for ASR",
                    "children": [
                        {
                            "name": "Neural Network Training Methods for ASR",
                            "children": [
                                {
                                    "name": " Multi-Domain Knowledge Distillation via Uncertainty-Matching for End-to-End ASR Models",
                                    "value": 1
                                },
                                {
                                    "name": " Learning a Neural Diff for Speech Models",
                                    "value": 1
                                },
                                {
                                    "name": " Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR Models",
                                    "value": 1
                                },
                                {
                                    "name": " Model-Agnostic Fast Adaptive Multi-Objective Balancing Algorithm for Multilingual Automatic Speech Recognition Model Training",
                                    "value": 1
                                },
                                {
                                    "name": " Towards Lifelong Learning of End-to-End ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Self-Adaptive Distillation for Multilingual Speech Recognition: Leveraging Student Independence",
                                    "value": 1
                                },
                                {
                                    "name": " Regularizing Word Segmentation by Creating Misspellings",
                                    "value": 1
                                },
                                {
                                    "name": " Multitask Training with Text Data for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Emitting Word Timings with HMM-Free End-to-End System in Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Scaling Laws for Acoustic Models",
                                    "value": 1
                                },
                                {
                                    "name": " Leveraging Non-Target Language Resources to Improve ASR Performance in a Target Language",
                                    "value": 1
                                },
                                {
                                    "name": " 4-Bit Quantization of LSTM-Based Speech Recognition Models",
                                    "value": 1
                                },
                                {
                                    "name": " Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation",
                                    "value": 1
                                },
                                {
                                    "name": " Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Variable Frame Rate Acoustic Models Using Minimum Error Reinforcement Learning",
                                    "value": 1
                                }
                            ],
                            "value": 15
                        }
                    ],
                    "value": 15
                },
                {
                    "name": "Prosodic Features and Structure",
                    "children": [
                        {
                            "name": "Prosodic Features and Structure",
                            "children": [
                                {
                                    "name": " How f0 and Phrase Position Affect Papuan Malay Word Identification",
                                    "value": 1
                                },
                                {
                                    "name": " On the Feasibility of the Danish Model of Intonational Transcription: Phonetic Evidence from Jutlandic Danish",
                                    "value": 1
                                },
                                {
                                    "name": " An Experiment in Paratone Detection in a Prosodically Annotated EAP Spoken Corpus",
                                    "value": 1
                                },
                                {
                                    "name": " ProsoBeast Prosody Annotation Tool",
                                    "value": 1
                                },
                                {
                                    "name": " Assessing the Use of Prosody in Constituency Parsing of Imperfect Transcripts",
                                    "value": 1
                                },
                                {
                                    "name": " Targeted and Targetless Neutral Tones in Taiwanese Southern Min",
                                    "value": 1
                                },
                                {
                                    "name": " The Interaction of Word Complexity and Word Duration in an Agglutinative Language",
                                    "value": 1
                                },
                                {
                                    "name": " Taiwan Min Nan (Taiwanese) Checked Tones Sound Change",
                                    "value": 1
                                },
                                {
                                    "name": " In-Group Advantage in the Perception of Emotions: Evidence from Three Varieties of German",
                                    "value": 1
                                },
                                {
                                    "name": " The LF Model in the Frequency Domain for Glottal Airflow Modelling Without Aliasing Distortion",
                                    "value": 1
                                },
                                {
                                    "name": " Parsing Speech for Grouping and Prominence, and the Typology of Rhythm",
                                    "value": 1
                                },
                                {
                                    "name": " Prosody of Case Markers in Urdu",
                                    "value": 1
                                },
                                {
                                    "name": " Articulatory Characteristics of Icelandic Voiced Fricative Lenition: Gradience, Categoricity, and Speaker/Gesture-Specific Effects",
                                    "value": 1
                                },
                                {
                                    "name": " Leveraging the Uniformity Framework to Examine Crosslinguistic Similarity for Long-Lag Stops in Spontaneous Cantonese-English Bilingual Speech",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        }
                    ],
                    "value": 14
                },
                {
                    "name": "INTERSPEECH 2021 Deep Noise Suppression Challenge",
                    "children": [
                        {
                            "name": "INTERSPEECH 2021 Deep Noise Suppression Challenge",
                            "children": [
                                {
                                    "name": " INTERSPEECH 2021 Deep Noise Suppression Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " A Simultaneous Denoising and Dereverberation Framework with Target Decoupling",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Noise Suppression with Non-Intrusive PESQNet Supervision Enabling the Use of Real Training Data",
                                    "value": 1
                                },
                                {
                                    "name": " DPCRN: Dual-Path Convolution Recurrent Network for Single Channel Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " DCCRN+: Channel-Wise Subband DCCRN with SNR Estimation for Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " DBNet: A Dual-Branch Network Architecture Processing on Spectrum and Waveform for Single-Channel Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Low-Delay Speech Enhancement Using Perceptually Motivated Target and Loss",
                                    "value": 1
                                },
                                {
                                    "name": " Lightweight Causal Transformer with Local Self-Attention for Real-Time Speech Enhancement",
                                    "value": 1
                                }
                            ],
                            "value": 8
                        }
                    ],
                    "value": 8
                },
                {
                    "name": "Emotion and Sentiment Analysis",
                    "children": [
                        {
                            "name": "Emotion and Sentiment Analysis  : I",
                            "children": [
                                {
                                    "name": " Speaker Attentive Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Separation of Emotional and Reconstruction Embeddings on Ladder Network to Improve Speech Emotion Recognition Robustness in Noisy Conditions",
                                    "value": 1
                                },
                                {
                                    "name": " M\u00b3: MultiModal Masking Applied to Sentiment Analysis",
                                    "value": 1
                                }
                            ],
                            "value": 3
                        },
                        {
                            "name": "Emotion and Sentiment Analysis : II",
                            "children": [
                                {
                                    "name": " Temporal Context in Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Learning Fine-Grained Cross Modality Excitement for Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit",
                                    "value": 1
                                },
                                {
                                    "name": " Multimodal Sentiment Analysis with Temporal Modality Attention",
                                    "value": 1
                                },
                                {
                                    "name": " Stochastic Process Regression for Cross-Cultural Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Emotion Recognition from Speech Using wav2vec 2.0 Embeddings",
                                    "value": 1
                                },
                                {
                                    "name": " Graph Isomorphism Network for Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Applying TDNN Architectures for Analyzing Duration Dependencies on Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Features and Neural Representations for Categorical Emotion Recognition from Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Leveraging Pre-Trained Language Model for Speech Sentiment Analysis",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Emotion and Sentiment Analysis : III",
                            "children": [
                                {
                                    "name": " Affect Recognition Through Scalogram and Multi-Resolution Cochleagram Features",
                                    "value": 1
                                },
                                {
                                    "name": " A Speech Emotion Recognition Framework for Better Discrimination of Confusions",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Emotion Recognition via Multi-Level Cross-Modal Distillation",
                                    "value": 1
                                },
                                {
                                    "name": " Audio-Visual Speech Emotion Recognition by Disentangling Emotion and Identity Attributes",
                                    "value": 1
                                },
                                {
                                    "name": " Parametric Distributions to Model Numerical Emotion Labels",
                                    "value": 1
                                },
                                {
                                    "name": " Metric Learning Based Feature Representation with Gated Fusion Model for Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Emotion Recognition with Multi-Task Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Generalized Dilated CNN Models for Depression Detection Using Inverted Vocal Tract Variables",
                                    "value": 1
                                },
                                {
                                    "name": " Learning Mutual Correlation in Multimodal Transformer for Speech Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Time-Frequency Representation Learning with Graph Convolutional Network for Dialogue-Level Speech Emotion Recognition",
                                    "value": 1
                                }
                            ],
                            "value": 10
                        }
                    ],
                    "value": 24
                },
                {
                    "name": "Multimodal Systems",
                    "children": [
                        {
                            "name": "Multimodal Systems",
                            "children": [
                                {
                                    "name": " Direct Multimodal Few-Shot Learning of Speech and Images",
                                    "value": 1
                                },
                                {
                                    "name": " Talk, Don\u2019t Write: A Study of Direct Speech-Based Image Retrieval",
                                    "value": 1
                                },
                                {
                                    "name": " A Fast Discrete Two-Step Learning Hashing for Scalable Cross-Modal Retrieval",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Modal Knowledge Distillation Method for Automatic Cued Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Attention-Based Keyword Localisation in Speech Using Visual Grounding",
                                    "value": 1
                                },
                                {
                                    "name": " Evaluation of Audio-Visual Alignments in Visually Grounded Speech Models",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Lip-Reading with Hierarchical Pyramidal Convolution and Self-Attention for Image Sequences with No Word Boundaries",
                                    "value": 1
                                },
                                {
                                    "name": " Cascaded Multilingual Audio-Visual Learning from Videos",
                                    "value": 1
                                },
                                {
                                    "name": " LiRA: Learning Visual Speech Representations from Audio Through Self-Supervision",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Audio-Visual Speech Recognition for Overlapping Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Audio-Visual Multi-Talker Speech Recognition in a Cocktail Party",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 11
                },
                {
                    "name": "Source Separation",
                    "children": [
                        {
                            "name": "Source Separation  : I",
                            "children": [
                                {
                                    "name": " Ultra Fast Speech Separation Model with Teacher Student Learning",
                                    "value": 1
                                },
                                {
                                    "name": " Group Delay Based Re-Weighted Sparse Recovery Algorithms for Robust and High-Resolution Source Separation in DOA Framework",
                                    "value": 1
                                },
                                {
                                    "name": " Continuous Speech Separation Using Speaker Inventory for Long Recording",
                                    "value": 1
                                },
                                {
                                    "name": " Crossfire Conditional Generative Adversarial Networks for Singing Voice Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Speech Separation Using Orthogonal Representation in Complex and Real Time-Frequency Domain",
                                    "value": 1
                                },
                                {
                                    "name": " Efficient and Stable Adversarial Learning Using Unpaired Data for Unsupervised Multichannel Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Stabilizing Label Assignment for Speech Separation by Self-Supervised Pre-Training",
                                    "value": 1
                                },
                                {
                                    "name": " Dual-Path Filter Network: Speaker-Aware Modeling for Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Investigation of Practical Aspects of Single Channel Speech Separation for ASR",
                                    "value": 1
                                },
                                {
                                    "name": " Implicit Filter-and-Sum Network for End-to-End Multi-Channel Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Generalized Spatio-Temporal RNN Beamformer for Target Speech Separation",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        },
                        {
                            "name": "Source Separation : II",
                            "children": [
                                {
                                    "name": " Online Blind Audio Source Separation Using Recursive Expectation-Maximization",
                                    "value": 1
                                },
                                {
                                    "name": " Empirical Analysis of Generalized Iterative Speech Separation Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Graph-PIT: Generalized Permutation Invariant Training for Continuous Separation of Arbitrary Numbers of Speakers",
                                    "value": 1
                                },
                                {
                                    "name": " Teacher-Student MixIT for Unsupervised and Semi-Supervised Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Few-Shot Learning of New Sound Classes for Target Sound Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " Binaural Speech Separation of Moving Speakers With Preserved Spatial Cues",
                                    "value": 1
                                },
                                {
                                    "name": " AvaTr: One-Shot Speaker Extraction with Transformers",
                                    "value": 1
                                },
                                {
                                    "name": " Vocal Harmony Separation Using Time-Domain Neural Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Verification-Based Evaluation of Single-Channel Speech Separation",
                                    "value": 1
                                },
                                {
                                    "name": " Improved Speech Separation with Time-and-Frequency Cross-Domain Feature Selection",
                                    "value": 1
                                },
                                {
                                    "name": " Robust Speaker Extraction Network Based on Iterative Refined Adaptation",
                                    "value": 1
                                },
                                {
                                    "name": " Neural Speaker Extraction with Speaker-Speech Cross-Attention Network",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Audio-Visual Speech Separation Based on Facial Motion",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        },
                        {
                            "name": "Source Separation : III",
                            "children": [
                                {
                                    "name": " Many-Speakers Single Channel Speech Separation with Optimal Permutation Training",
                                    "value": 1
                                },
                                {
                                    "name": " Combating Reverberation in NTF-Based Speech Separation Using a Sub-Source Weighted Multichannel Wiener Filter and Linear Prediction",
                                    "value": 1
                                },
                                {
                                    "name": " A Hands-On Comparison of DNNs for Dialog Separation Using Transfer Learning from Music Source Separation",
                                    "value": 1
                                },
                                {
                                    "name": " GlobalPhone Mix-To-Separate Out of 2: A Multilingual 2000 Speakers Mixtures Database for Speech Separation",
                                    "value": 1
                                }
                            ],
                            "value": 4
                        }
                    ],
                    "value": 28
                },
                {
                    "name": "Speaker Diarization",
                    "children": [
                        {
                            "name": "Speaker Diarization  : I",
                            "children": [
                                {
                                    "name": " End-to-End Neural Diarization: From Transformer to Conformer",
                                    "value": 1
                                },
                                {
                                    "name": " Three-Class Overlapped Speech Detection Using a Convolutional Recurrent Neural Network",
                                    "value": 1
                                },
                                {
                                    "name": " Online Speaker Diarization Equipped with Discriminative Modeling and Guided Inference",
                                    "value": 1
                                },
                                {
                                    "name": " Semi-Supervised Training with Pseudo-Labeling for End-To-End Neural Diarization",
                                    "value": 1
                                },
                                {
                                    "name": " Adapting Speaker Embeddings for Speaker Diarisation",
                                    "value": 1
                                },
                                {
                                    "name": " Scenario-Dependent Speaker Diarization for DIHARD-III Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " End-To-End Speaker Segmentation for Overlap-Aware Resegmentation",
                                    "value": 1
                                },
                                {
                                    "name": " Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers",
                                    "value": 1
                                },
                                {
                                    "name": " A Thousand Words are Worth More Than One Recording: //Word-Embedding// Based Speaker Change Detection",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        },
                        {
                            "name": "Speaker Diarization : II",
                            "children": [
                                {
                                    "name": " LEAP Submission for the Third DIHARD Diarization Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Investigation of Spatial-Acoustic Features for Overlapping Speech Detection in Multiparty Meetings",
                                    "value": 1
                                },
                                {
                                    "name": " Target-Speaker Voice Activity Detection with Improved i-Vector Estimation for Unknown Number of Speaker",
                                    "value": 1
                                },
                                {
                                    "name": " ECAPA-TDNN Embeddings for Speaker Diarization",
                                    "value": 1
                                },
                                {
                                    "name": " Advances in Integration of End-to-End Neural and Clustering-Based Diarization for Real Conversational Speech",
                                    "value": 1
                                },
                                {
                                    "name": " The Third DIHARD Diarization Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Robust End-to-End Speaker Diarization with Conformer and Additive Margin Penalty",
                                    "value": 1
                                },
                                {
                                    "name": " Anonymous Speaker Clusters: Making Distinctions Between Anonymised Speech Recordings with Clustering Interface",
                                    "value": 1
                                },
                                {
                                    "name": " Speaker Diarization Using Two-Pass Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        }
                    ],
                    "value": 18
                },
                {
                    "name": "Speech Production",
                    "children": [
                        {
                            "name": "Speech Production : II",
                            "children": [
                                {
                                    "name": " A Simplified Model for the Vocal Tract of [s] with Inclined Incisors",
                                    "value": 1
                                },
                                {
                                    "name": " Vocal-Tract Models to Visualize the Airstream of Human Breath and Droplets While Producing Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Using Transposed Convolution for Articulatory-to-Acoustic Conversion from Real-Time MRI Data",
                                    "value": 1
                                },
                                {
                                    "name": " Comparison Between Lumped-Mass Modeling and Flow Simulation of the Reed-Type Artificial Vocal Fold",
                                    "value": 1
                                },
                                {
                                    "name": " Inhalations in Speech: Acoustic and Physiological Characteristics",
                                    "value": 1
                                },
                                {
                                    "name": " Model-Based Exploration of Linking Between Vowel Articulatory Space and Acoustic Space",
                                    "value": 1
                                },
                                {
                                    "name": " Take a Breath: Respiratory Sounds Improve Recollection in Synthetic Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Modeling Sensorimotor Adaptation in Speech Through Alterations to Forward and Inverse Models",
                                    "value": 1
                                },
                                {
                                    "name": " Mixture of Orthogonal Sequences Made from Extended Time-Stretched Pulses Enables Measurement of Involuntary Voice Fundamental Frequency Response to Pitch Perturbation",
                                    "value": 1
                                }
                            ],
                            "value": 9
                        },
                        {
                            "name": "Speech Production  : I",
                            "children": [
                                {
                                    "name": " Towards the Prediction of the Vocal Tract Shape from the Sequence of Phonemes to be Articulated",
                                    "value": 1
                                },
                                {
                                    "name": " Comparison of the Finite Element Method, the Multimodal Method and the Transmission-Line Model for the Computation of Vocal Tract Transfer Functions",
                                    "value": 1
                                },
                                {
                                    "name": " Effects of Time Pressure and Spontaneity on Phonotactic Innovations in German Dialogues",
                                    "value": 1
                                },
                                {
                                    "name": " Importance of Parasagittal Sensor Information in Tongue Motion Capture Through a Diphonic Analysis",
                                    "value": 1
                                },
                                {
                                    "name": " Learning Robust Speech Representation with an Articulatory-Regularized Variational Autoencoder",
                                    "value": 1
                                },
                                {
                                    "name": " Changes in Glottal Source Parameter Values with Light to Moderate Physical Load",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        }
                    ],
                    "value": 15
                },
                {
                    "name": "Tools, Corpora and Resources",
                    "children": [
                        {
                            "name": "Tools, Corpora and Resources",
                            "children": [
                                {
                                    "name": " Spoken ObjectNet: A Bias-Controlled Spoken Caption Dataset",
                                    "value": 1
                                },
                                {
                                    "name": " The Multilingual TEDx Corpus for Speech Recognition and Translation",
                                    "value": 1
                                },
                                {
                                    "name": " Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered Language for Universal Phone Recognition Experiments",
                                    "value": 1
                                },
                                {
                                    "name": " AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario",
                                    "value": 1
                                },
                                {
                                    "name": " GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio",
                                    "value": 1
                                },
                                {
                                    "name": " Look Who\u2019s Talking: Active Speaker Detection in the Wild",
                                    "value": 1
                                },
                                {
                                    "name": " AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Children\u2019s Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Human-in-the-Loop Efficiency Analysis for Binary Classification in Edyson",
                                    "value": 1
                                },
                                {
                                    "name": " Annotation Confidence vs. Training Sample Size: Trade-Off Solution for Partially-Continuous Categorical Emotion Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Europarl-ASR: A Large Corpus of Parliamentary Debates for Streaming ASR Benchmarking and Speech Data Filtering/Verbatimization",
                                    "value": 1
                                },
                                {
                                    "name": " Towards Automatic Speech to Sign Language Generation",
                                    "value": 1
                                },
                                {
                                    "name": " kosp2e: Korean Speech to English Translation Corpus",
                                    "value": 1
                                },
                                {
                                    "name": " speechocean762: An Open-Source Non-Native English Speech Corpus for Pronunciation Assessment",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "Non-Autoregressive Sequential Modeling for Speech Processing",
                    "children": [
                        {
                            "name": "Non-Autoregressive Sequential Modeling for Speech Processing",
                            "children": [
                                {
                                    "name": " An Improved Single Step Non-Autoregressive Transformer for Automatic Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain",
                                    "value": 1
                                },
                                {
                                    "name": " Pushing the Limits of Non-Autoregressive Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies",
                                    "value": 1
                                },
                                {
                                    "name": " Relaxing the Conditional Independence Assumption of CTC-Based ASR by Conditioning on Intermediate Predictions",
                                    "value": 1
                                },
                                {
                                    "name": " Toward Streaming ASR with Non-Autoregressive Insertion-Based Model",
                                    "value": 1
                                },
                                {
                                    "name": " Layer Pruning on Demand with Intermediate CTC",
                                    "value": 1
                                },
                                {
                                    "name": " Real-Time End-to-End Monaural Multi-Speaker Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " Streaming End-to-End ASR Based on Blockwise Non-Autoregressive Models",
                                    "value": 1
                                },
                                {
                                    "name": " TalkNet: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis",
                                    "value": 1
                                },
                                {
                                    "name": " Align-Denoise: Single-Pass Non-Autoregressive Speech Recognition",
                                    "value": 1
                                },
                                {
                                    "name": " VAENAR-TTS: Variational Auto-Encoder Based Non-AutoRegressive Text-to-Speech Synthesis",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "The ADReSSo Challenge",
                    "children": [
                        {
                            "name": "The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only",
                            "children": [
                                {
                                    "name": " Detecting Cognitive Decline Using Speech Only: The ADReSSo Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Influence of the Interviewer on the Automatic Assessment of Alzheimer\u2019s Disease in the Context of the ADReSSo Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " WavBERT: Exploiting Semantic and Non-Semantic Speech Using Wav2vec and BERT for Dementia Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Alzheimer Disease Recognition Using Speech-Based Embeddings From Pre-Trained Models",
                                    "value": 1
                                },
                                {
                                    "name": " Comparing Acoustic-Based Approaches for Alzheimer\u2019s Disease Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Alzheimer\u2019s Disease Detection from Spontaneous Speech Through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models",
                                    "value": 1
                                },
                                {
                                    "name": " Using the Outputs of Different Automatic Speech Recognition Paradigms for Acoustic- and BERT-Based Alzheimer\u2019s Dementia Detection Through Spontaneous Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Tackling the ADRESSO Challenge 2021: The MUET-RMIT System for Alzheimer\u2019s Dementia Recognition from Spontaneous Speech",
                                    "value": 1
                                },
                                {
                                    "name": " Alzheimer\u2019s Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Detection and Assessment of Alzheimer Disease Using Speech and Language Technologies in Low-Resource Scenarios",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Detection of Alzheimer\u2019s Disease Using Spontaneous Speech Only",
                                    "value": 1
                                },
                                {
                                    "name": " Modular Multi-Modal Attention Network for Alzheimer\u2019s Disease Detection Using Patient Audio and Language Data",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 12
                },
                {
                    "name": "Non-Native Speech",
                    "children": [
                        {
                            "name": "Non-Native Speech",
                            "children": [
                                {
                                    "name": " Cross-Linguistic Perception of the Japanese Singleton/Geminate Contrast: Korean, Mandarin and Mongolian Compared",
                                    "value": 1
                                },
                                {
                                    "name": " Detection of Lexical Stress Errors in Non-Native (L2) English with Data Augmentation and Attention",
                                    "value": 1
                                },
                                {
                                    "name": " Testing Acoustic Voice Quality Classification Across Languages and Speech Styles",
                                    "value": 1
                                },
                                {
                                    "name": " Acquisition of Prosodic Focus Marking by Three- to Six-Year-Old Children Learning Mandarin Chinese",
                                    "value": 1
                                },
                                {
                                    "name": " Adaptive Listening Difficulty Detection for L2 Learners Through Moderating ASR Resources",
                                    "value": 1
                                },
                                {
                                    "name": " F\u2080 Patterns of L2 English Speech by Mandarin Chinese Learners",
                                    "value": 1
                                },
                                {
                                    "name": " A Neural Network-Based Noise Compensation Method for Pronunciation Assessment",
                                    "value": 1
                                },
                                {
                                    "name": " Phonetic Distance and Surprisal in Multilingual Priming: Evidence from Slavic",
                                    "value": 1
                                },
                                {
                                    "name": " A Preliminary Study on Discourse Prosody Encoding in L1 and L2 English Spontaneous Narratives",
                                    "value": 1
                                },
                                {
                                    "name": " Transformer Based End-to-End Mispronunciation Detection and Diagnosis",
                                    "value": 1
                                },
                                {
                                    "name": " L1 Identification from L2 Speech Using Neural Spectrogram Analysis",
                                    "value": 1
                                }
                            ],
                            "value": 11
                        }
                    ],
                    "value": 11
                },
                {
                    "name": "Speech Type Classification and Diagnosis",
                    "children": [
                        {
                            "name": "Speech Type Classification and Diagnosis",
                            "children": [
                                {
                                    "name": " An Agent for Competing with Humans in a Deceptive Game Based on Vocal Cues",
                                    "value": 1
                                },
                                {
                                    "name": " A Multi-Branch Deep Learning Network for Automated Detection of COVID-19",
                                    "value": 1
                                },
                                {
                                    "name": " RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform",
                                    "value": 1
                                },
                                {
                                    "name": " Fake Audio Detection in Resource-Constrained Settings Using Microfeatures",
                                    "value": 1
                                },
                                {
                                    "name": " Coughing-Based Recognition of Covid-19 with Spatial Attentive ConvLSTM Recurrent Neural Networks",
                                    "value": 1
                                },
                                {
                                    "name": " Knowledge Distillation for Singing Voice Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Age Estimation with Speech-Age Model for Heterogeneous Speech Datasets",
                                    "value": 1
                                },
                                {
                                    "name": " Open-Set Audio Classification with Limited Training Resources Based on Augmentation Enhanced Variational Auto-Encoder GAN with Detection-Classification Joint Training",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Spectral-Cepstral Fusion for Shouted and Normal Speech Classification",
                                    "value": 1
                                },
                                {
                                    "name": " Automatic Detection of Shouted Speech Segments in Indian News Debates",
                                    "value": 1
                                },
                                {
                                    "name": " Generalized Spoofing Detection Inspired from Audio Generation Artifacts",
                                    "value": 1
                                },
                                {
                                    "name": " Overlapped Speech Detection Based on Spectral and Spatial Feature Fusion",
                                    "value": 1
                                }
                            ],
                            "value": 12
                        }
                    ],
                    "value": 12
                },
                {
                    "name": "Spoken Term Detection    Voice Search",
                    "children": [
                        {
                            "name": "Spoken Term Detection    Voice Search",
                            "children": [
                                {
                                    "name": " Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study",
                                    "value": 1
                                },
                                {
                                    "name": " Paraphrase Label Alignment for Voice Application Retrieval in Spoken Language Understanding",
                                    "value": 1
                                },
                                {
                                    "name": " Personalized Keyphrase Detection Using Speaker and Environment Information",
                                    "value": 1
                                },
                                {
                                    "name": " Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation",
                                    "value": 1
                                },
                                {
                                    "name": " Few-Shot Keyword Spotting in Any Language",
                                    "value": 1
                                },
                                {
                                    "name": " Text Anchor Based Metric Learning for Small-Footprint Keyword Spotting",
                                    "value": 1
                                },
                                {
                                    "name": " A Meta-Learning Approach for User-Defined Spoken Term Classification with Varying Classes and Examples",
                                    "value": 1
                                },
                                {
                                    "name": " Auxiliary Sequence Labeling Tasks for Disfluency Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Energy-Friendly Keyword Spotting System Using Add-Based Convolution",
                                    "value": 1
                                },
                                {
                                    "name": " The 2020 Personalized Voice Trigger Challenge: Open Datasets, Evaluation Metrics, Baseline System and Results",
                                    "value": 1
                                },
                                {
                                    "name": " Auto-KWS 2021 Challenge: Task, Datasets, and Baselines",
                                    "value": 1
                                },
                                {
                                    "name": " Keyword Transformer: A Self-Attention Model for Keyword Spotting",
                                    "value": 1
                                },
                                {
                                    "name": " Teaching Keyword Spotters to Spot New Keywords with Limited Examples",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "Voice Anti-Spoofing and Countermeasure",
                    "children": [
                        {
                            "name": "Voice Anti-Spoofing and Countermeasure",
                            "children": [
                                {
                                    "name": " A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection",
                                    "value": 1
                                },
                                {
                                    "name": " An Initial Investigation for Detecting Partially Spoofed Audio",
                                    "value": 1
                                },
                                {
                                    "name": " Siamese Network with wav2vec Feature for Spoofing Speech Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Cross-Database Replay Detection in Terminal-Dependent Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " The Effect of Silence and Dual-Band Fusion in Anti-Spoofing System",
                                    "value": 1
                                },
                                {
                                    "name": " Pairing Weak with Strong: Twin Models for Defending Against Adversarial Attack on Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Attention-Based Convolutional Neural Network for ASV Spoofing Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Voting for the Right Answer: Adversarial Defense for Speaker Verification",
                                    "value": 1
                                },
                                {
                                    "name": " Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing",
                                    "value": 1
                                },
                                {
                                    "name": " Representation Learning to Classify and Detect Adversarial Attacks Against Speaker and Speech Recognition Systems",
                                    "value": 1
                                },
                                {
                                    "name": " An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems",
                                    "value": 1
                                },
                                {
                                    "name": " Channel-Wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks",
                                    "value": 1
                                },
                                {
                                    "name": " Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection",
                                    "value": 1
                                }
                            ],
                            "value": 13
                        }
                    ],
                    "value": 13
                },
                {
                    "name": "Voice Activity Detection",
                    "children": [
                        {
                            "name": "Voice Activity Detection",
                            "children": [
                                {
                                    "name": " Unsupervised Representation Learning for Speech Activity Detection in the Fearless Steps Challenge 2021",
                                    "value": 1
                                },
                                {
                                    "name": " The Application of Learnable STRF Kernels to the 2021 Fearless Steps Phase-03 SAD Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Speech Activity Detection Based on Multilingual Speech Recognition System",
                                    "value": 1
                                },
                                {
                                    "name": " Voice Activity Detection with Teacher-Student Domain Emulation",
                                    "value": 1
                                },
                                {
                                    "name": " EML Online Speech Activity Detection for the Fearless Steps Challenge Phase-III",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        }
                    ],
                    "value": 5
                },
                {
                    "name": "Keyword Search and Spoken Language Processing",
                    "children": [
                        {
                            "name": "Keyword Search and Spoken Language Processing",
                            "children": [
                                {
                                    "name": " Device Playback Augmentation with Echo Cancellation for Keyword Spotting",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Open Vocabulary Keyword Search",
                                    "value": 1
                                },
                                {
                                    "name": " Semantic Sentence Similarity: Size does not Always Matter",
                                    "value": 1
                                },
                                {
                                    "name": " Spoken Term Detection and Relevance Score Estimation Using Dot-Product of Pronunciation Embeddings",
                                    "value": 1
                                },
                                {
                                    "name": " Toward Genre Adapted Closed Captioning",
                                    "value": 1
                                }
                            ],
                            "value": 5
                        }
                    ],
                    "value": 5
                },
                {
                    "name": "Applications in Transcription, Education and Learning",
                    "children": [
                        {
                            "name": "Applications in Transcription, Education and Learning",
                            "children": [
                                {
                                    "name": " Weakly-Supervised Word-Level Pronunciation Error Detection in Non-Native English Speech",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Speaker-Attributed ASR with Transformer",
                                    "value": 1
                                },
                                {
                                    "name": " Understanding Medical Conversations: Rich Transcription, Confidence Scores & Information Extraction",
                                    "value": 1
                                },
                                {
                                    "name": " Phone-Level Pronunciation Scoring for Spanish Speakers Learning English Using a GOP-DNN System",
                                    "value": 1
                                },
                                {
                                    "name": " Explore wav2vec 2.0 for Mispronunciation Detection",
                                    "value": 1
                                },
                                {
                                    "name": " Lexical Density Analysis of Word Productions in Japanese English Using Acoustic Word Embeddings",
                                    "value": 1
                                },
                                {
                                    "name": " Deep Feature Transfer Learning for Automatic Pronunciation Assessment",
                                    "value": 1
                                },
                                {
                                    "name": " Multilingual Speech Evaluation: Case Studies on English, Malay and Tamil",
                                    "value": 1
                                },
                                {
                                    "name": " A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis",
                                    "value": 1
                                },
                                {
                                    "name": " The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech",
                                    "value": 1
                                },
                                {
                                    "name": " End-to-End Rich Transcription-Style Automatic Speech Recognition with Semi-Supervised Learning",
                                    "value": 1
                                },
                                {
                                    "name": " \u201cYou don\u2019t understand me!\u201d: Comparing ASR Results for L1 and L2 Speakers of Swedish",
                                    "value": 1
                                },
                                {
                                    "name": " NeMo Inverse Text Normalization: From Development to Production",
                                    "value": 1
                                },
                                {
                                    "name": " Improvement of Automatic English Pronunciation Assessment with Small Number of Utterances Using Sentence Speakability",
                                    "value": 1
                                }
                            ],
                            "value": 14
                        }
                    ],
                    "value": 14
                },
                {
                    "name": "INTERSPEECH 2021 Acoustic Echo Cancellation Challenge",
                    "children": [
                        {
                            "name": "INTERSPEECH 2021 Acoustic Echo Cancellation Challenge",
                            "children": [
                                {
                                    "name": " INTERSPEECH 2021 Acoustic Echo Cancellation Challenge",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Echo Cancellation with Cross-Domain Learning",
                                    "value": 1
                                },
                                {
                                    "name": " F-T-LSTM Based Complex Network for Joint Acoustic Echo Cancellation and Speech Enhancement",
                                    "value": 1
                                },
                                {
                                    "name": " Y\u00b2-Net FCRN for Acoustic Echo and Noise Suppression",
                                    "value": 1
                                },
                                {
                                    "name": " Acoustic Echo Cancellation Using Deep Complex Neural Network with Nonlinear Magnitude Compression and Phase Information",
                                    "value": 1
                                },
                                {
                                    "name": " Nonlinear Acoustic Echo Cancellation with Deep Learning",
                                    "value": 1
                                }
                            ],
                            "value": 6
                        }
                    ],
                    "value": 6
                }
            ],
            "width": "80%",
            "height": "80%",
            "label": {
                "show": true,
                "position": "inside",
                "margin": 8
            },
            "upperlabel": {
                "show": true,
                "position": "inside",
                "margin": 8
            },
            "leafDepth": 1,
            "drillDownIcon": "\u25b6",
            "roam": true,
            "nodeClick": "zoomToNode",
            "zoomToNodeRatio": 0.1024,
            "visualMin": 500,
            "colorMappingBy": "index",
            "visibleMin": 10
        }
    ],
    "legend": [
        {
            "data": [
                "option"
            ],
            "selected": {
                "option": true
            },
            "show": false,
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "showContent": true,
        "alwaysShowContent": false,
        "showDelay": 0,
        "hideDelay": 100,
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0,
        "padding": 5
    },
    "title": [
        {
            "text": "Interspeech 2021 \u8bba\u6587\u5206\u5e03",
            "subtext": "2021/9/2",
            "left": "leafDepth",
            "padding": 5,
            "itemGap": 10
        }
    ]
};
        chart_f8402b66578a40179f060f6f7c91380f.setOption(option_f8402b66578a40179f060f6f7c91380f);
    </script>
</body>
</html>
